# Species

## Working with vegetation data

To begin with, we will query plot level NASIS data using the query outlined in [Accessing plot level vegetation data](#plotveg). Then, run ```ecositer::vegStaticNASIS()``` and ```ecositer::formatted_veg_df()```. See the 

Vegetation data QC is a critical step in ecological data analysis. The USDA plants database improves vegetation data quality, ensuring proper scientific names are used, but additional QC must be performed. One of the primary tasks will be dealing with identifications to different taxonomic levels (i.e., genus, species, and subspecies). Statistical approaches think of each class separately and therefore do not recognize any similarity between taxonomic levels. For example, statistical analyses do not recognize any relationship between Pinus, Pinus contorta, and Pinus contorta var. murrayana. For this reason, you will need to determine how to modify your data based on the characteristics of your data set and expert knowledge. This will likely need to be done on a species-by-species basis. The ultimate goal is to group all of the observations of one organism into one class. 

Below is an example of this process and code you can use to assist:

To begin with, I will look at all of the plant names used: 



## Mapping the location of species

Let's take a look at the location of species. To do this we will query plot level NASIS data using the query outlined in [Accessing plot level vegetation data](#plotveg).

Once you have queried, you can filter your dataset for any species of interest. I am going to search for a genus - *Artemisia* (sagebrush). Ultimately, we will produce a map that shows the distribution of all the species of *Artemisia*. 

```{r, echo=FALSE, message=FALSE, warning=FALSE}
veg_data <- fetchVegdata(dsn = "C:/Users/Nathan.Roe/Documents/SEKI/CA792_veg.sqlite", SS = FALSE)
```

```{r}
veg_data <- fetchVegdata(dsn = "C:/Users/Nathan.Roe/Documents/SEKI/CA792_veg.sqlite", SS = FALSE)

artemesia_df <-
  veg_data$vegplotspecies %>% filter(plantsciname %in% str_subset(veg_data$vegplotspecies$plantsciname, "Artemisia")) %>%
  select(siteiid, plantsciname)
```

Query for *Artemisia* and create a spatial dataframe with coordinates 
```{r}
artemesia_df <-
  veg_data$vegplotspecies %>% filter(plantsciname %in% str_subset(veg_data$vegplotspecies$plantsciname, "Artemisia")) %>%
  select(siteiid, plantsciname)

artemesia_location <-
  veg_data$vegplotlocation %>% dplyr::filter(siteiid %in% artemesia_df$siteiid) %>% select(siteiid, utmzone, utmeasting, utmnorthing) %>%
  dplyr::left_join(artemesia_df) %>% st_as_sf(coords = c('utmeasting', 'utmnorthing'),
                                              crs = st_crs(32611))
```

Create a list of dataframes based on the different 



```{r}
veg_data <- fetchVegdata(dsn = "C:/Users/Nathan.Roe/Documents/SEKI/CA792_veg.sqlite", SS = FALSE)

artemesia_df <-
  veg_data$vegplotspecies %>% filter(plantsciname %in% str_subset(veg_data$vegplotspecies$plantsciname, "Artemisia")) %>%
  select(siteiid, plantsciname)

artemesia_location <-
  veg_data$vegplotlocation %>% dplyr::filter(siteiid %in% artemesia_df$siteiid) %>% select(siteiid, utmzone, utmeasting, utmnorthing) %>%
  dplyr::left_join(artemesia_df) %>% st_as_sf(coords = c('utmeasting', 'utmnorthing'),
                                              crs = st_crs(32611))

artemesia_location_split <-  split(artemesia_location, artemesia_location$plantsciname)


my_colors <- RColorBrewer::brewer.pal(n = length(artemesia_location_split), name = 'Set1')


mapview::mapView(artemesia_location_split, col.regions = my_colors)
```






It can be really useful to create a stored version of your selected set. That way, if you are frequently changing between different different selected sets, you do not have to clear your selected set and run a new query. This can be done by saving your selected set as an SQlite database. This allows you to call the saved SQlite database in SoilDB functions.

Let's look at how we can create a stored SQlite database. 

```{r, eval=FALSE}
soilDB::createStaticNASIS(SS = TRUE, tables = 
      soilDB::get_NASIS_table_name_by_purpose(c("area", "legend", "mapunit", "datamapunit", "component", "metadata", "lookup", "nasis")),
      output_path = "C:/Users/Nathan.Roe/Documents/SEKI/CA792_veg.sqlite")
```

Note: The tables listed in the get_NASIS_table_name_by_purpose argument should cover the majority of situations. If you run into an issue, though, soilDB will likely name a specific table that is missing. If that happens, you will have to add the table to the character vector. 

Once you have stored your SQlite database, you can call it using the soilDB functions. The default argument in ```fetchNASIS()``` and other SoilDB functions is ```SS = TRUE```. We are going to change that to false and identify the location of the SQlite database in the dsn argument. 

```{r, eval=FALSE}
my.components.MLRA <- fetchNASIS(from = "components", duplicates = T, dsn = "C:/Users/Nathan.Roe/Documents/SEKI/CA792_veg.sqlite", SS = FALSE)
```

This can be extremely useful when you have multiple selected sets that you are working with. 