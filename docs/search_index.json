[["index.html", "NRCS Ecologist FAQs Chapter 1 Introduction 1.1 Overview 1.2 ODBC Connection 1.3 Standard dataset/packages", " NRCS Ecologist FAQs Nathan Roe - nateroe@gmail.com 2023-08-16 Chapter 1 Introduction This documents outlines common methodologies used by NRCS Ecologists. It is intended to be an educational resource and to develop best practice standards. This is intended to be a living document. If you have recommendations for best practices or additional practices that should be added, please let me know! 1.1 Overview This document is divided into 4 sections: mapunits, components, plots, and ecosites. Within those sections are commonly used methodologies relating to the section concept. For example, within the components section are methodologies relating to the use of components (i.e., What are the ecological characteristics of components?). Much of this methodology relies on a combination of NASIS and R. It is my objective to make the R examples clear enough that someone with minimal to no experience with R can reproduce these examples. 1.2 ODBC Connection As mentioned, these methodologies frequently utilize R and NASIS. To accomplish this, you will need to have R installed and establish an ODBC connection to NASIS. This is outlined in detail by the NRCS Stats for Soil Survey pre-course assignment. 1.3 Standard dataset/packages For many of the examples in this document, we will be using the same dataset and packages. I will refer to this as the Standard Dataset. I will provide links back to this section where the Standard Dataset is used. Load standard packages library(soilDB) library(dplyr) library(aqp) library(sf) library(stringr) library(ggplot2) library(maps) Step 1. Determine the mapunits of interest using the Mapunit in MLRA tool for MLRA 18 with a 15% Membership. This tool is discussed in detail in What mapunits are in an MLRA?. Step 2. Take the group of mapunits and enter them into Query &gt; NSSC Pangaea &gt; Area/Legend/Mapunit/DMU by record ID - LMAPUNITIID list. Run against National Database: Run against Local: effec Step 3. Fetch NASIS data my.components.MLRA &lt;- fetchNASIS(from = &quot;components&quot;, duplicates = TRUE) Note on the duplicates = TRUE argument: fetchNASIS(from = \"components\") can access two hierarchical levels of data. The higher hierarchical level data is mapunit/soil survey area data. The lower hierarchical level data is component level data. By default, fetchNASIS(from = \"components\") accesses data at the component level. At times, we want to access data at a higher level (mapunit/soil survey area). When we want to access higher level data, the component level data must be nested within the higher level data. If there is a multiple:1 relationship between the higher level data and the component level data, duplication occurs. The multiple:1 relationship between higher level data and the component level data occurs because of MLRA mapunits - mapunits that occur across soil survey areas. With MLRA mapunits, components can be used in multiple mapunits/soil survey areas. The take-home message is that you need to use the duplicates = TRUE to access mapunit/soil survey area data. This argument will cause duplication of component level data for MLRA mapunits where the component is used in multiple mapunits/soil survey areas. This is will provide you with the same data that I am using, if you want to following along exactly. You will likely find it to be of greater utility to use map units relevant to you, though. You can also use different Queries that do not take map units as input. Many Queries will return the same fields as the Query in Step 2 (i.e., the Query, NSSC Pangaea &gt; Area/Legend/Mapunit/DMU by record ID - COIID will also work with most of the methodologies outlined if you prefer to query by Component ID). NASIS Queries do vary from each other, though, so it depends on the intracies of the Query. "],["mapunits.html", "Chapter 2 Mapunits 2.1 What mapunits are in an MLRA? 2.2 What mapunits are in a Soil Survey Area? 2.3 Mapping mapunits", " Chapter 2 Mapunits This section deals with mapunits. Mapunits have limited application for ecological work because they are broad concepts. Mapunits frequently contain multiple components, each occurring on different parts of the landscape and having different soil properties. Ecosites are correlated to components rather than mapunits because of the variability of mapunits. It should be noted that mapunits are spatially delineated, though, whereas components are not. Therefore, an attempt to map ecosites would rely heavily on mapunit delineations. An example of this can be seen on Web Soil Survey. Web Soil Survey can be used to map ecosites. These maps use mapunit delineations and show the ecosites that are correlated to the dominant component in that mapunit. For the purpose of this document, mapunits are primarily used as intermediate steps in different methodologies. For example, some NASIS Reports are particularly useful and require mapunits as input. Therefore, determining what mapunits are in your area of interest is helpful. The NRCS has four soil mapping products: SSURGO, gSSURGO, STATSGO, and gNATSGO. SSURGO is the most detailed product but is not available in all areas of the country. The resolution of SSURGO data ranges from 1:12,0000 to 1:63,360. gSSURGO is a gridded (rasterized) version of SSURGO - hence the “g” prefix. It covers the same areas as SSURGO but is gridded at a 10-meter cell size. STATSGO is a less detailed product but is available across all parts of the US. The resolution is 1:250,0000 in the continental US, Hawaii, Puerto Rico and the Virgin Islands. In Alaska, the resolution is 1:1,000,000. gNATSGO is a gridded combination of SSURGO and STATSGO. gNATSGO is primarily SSURGO data, but where SSURGO is unavailable, STATSGO is used to fill the gaps. The state-wide geodatabases are 10-meter cell sizes and the CONUS database is a 30-meter cell size. Data mapunits are the internal structure of mapunits. Data mapunits contain the mapunit component data as well as some information about the data mapunit itself. Over time, changes are sometimes made to data mapunits. Examples include adding a mapunit component to a mapunit, changing the particle size percentages of a mapunit component, or as a result of mapunits being renamed and aggregated as a result of transitioning into MLRA mapunits. When changes are made to a data mapunit, a new data mapunit is created. This new data mapunit becomes the representative data mapunit and the old data mapunit becomes a non-representative data mapunit. By doing this, a historical record of data mapunits is created, that way past versions are not lost. For ecological site work, we are almost always interested in working with representative data mapunits because they are the most up-to-date data available. 2.1 What mapunits are in an MLRA? If your MLRA uses primarily SSURGO data, the Mapunit in MLRA tool is the best option. It allow you to simply enter your MLRA of interest and define what percent of the total mapunit acreage must be within your MLRA for the mapunit to be considered a member of your MLRA of interest. Note that this tool will make two groups of mapunits if there are more than 2,100 mapunits. This happens because most NASIS queries do not allow for more than 2,100 mapunits to be included in a query. Why not use a NASIS Query that queries components by MLRA, like NASIS &gt; Queries &gt; NSSC Pangaea &gt; Area/Legend/Mapunit/DMU by MLRA? Unfortunately, this is not the most reliable way to determine what mapunits are in an MLRA. Mapunits are assigned to an MLRA via the mapunit area overlap table. These tables are not perfectly populated. Some mapunits are not assigned to an MLRA and others could be assigned to multiple MLRAs. For this reason, using a spatial intersection, as is done in the ‘Mapunit in MLRA tool’ is the preferred approach. Components are assigned from the same mapunit area overlap tables and therefore suffer from imperfect population of mapunit overlap tables also. Components 2.2 What mapunits are in a Soil Survey Area? Queries by Soil Survey Area are much more reliable than queries by MLRA. As previously mentioned, queries by MLRA are not ideal because the mapunit overlap tables are imperfectly populated. The Soil Survey area corresponds to the legend, and this means that components are reliably associated with Soil Survey Areas. Therefore, let’s use the following: NASIS &gt; Query &gt; NSSC Pangaea &gt; Area/Legend/Mapunit/DMU/Pedon/Site/ by areasymbol. Run against National Run against Local Acquire component names and IDs using R. Load the soilDB package and fetch NASIS data library(soilDB) my.mapunits.SSA &lt;- fetchNASIS(from = &quot;components&quot;, duplicates = T) ## Warning: Horizon top depths contain NA! Check depth logic with ## aqp::checkHzDepthLogic() ## Warning: Horizon bottom depths contain NA! Check depth logic with ## aqp::checkHzDepthLogic() ## Warning in `hzidname&lt;-`(`*tmp*`, value = &quot;chiid&quot;): horizon ID name (chiid) not ## unique. unique ID not changed. Look at the mapunits - the head() function shows just the first six records. Remove the head() function to see all the component names head(my.mapunits.SSA$muname) ## [1] &quot;Water&quot; ## [2] &quot;Rock outcrop, granitic crags-Typic Cryorthents complex, 30 to 100 percent slopes&quot; ## [3] &quot;Rock outcrop, granitic crags-Typic Cryorthents complex, 30 to 100 percent slopes&quot; ## [4] &quot;Rock outcrop, granitic crags-Typic Cryorthents complex, 30 to 100 percent slopes&quot; ## [5] &quot;Rock outcrop, metamorphic crags-Typic Cryorthents, metamorphic complex, 30 to 90 percent slopes&quot; ## [6] &quot;Rock outcrop, metamorphic crags-Typic Cryorthents, metamorphic complex, 30 to 90 percent slopes&quot; Look at the mapunit keys head(my.mapunits.SSA$mukey) ## [1] 2766840 2766852 2766852 2766852 2766853 2766853 2.3 Mapping mapunits Using Soil Web and R. "],["components.html", "Chapter 3 Components 3.1 Identify components in MLRA? 3.2 Identify components in Soil Survey Area? 3.3 Existing component, ecosite correlations 3.4 Components correlated to an ecosite of interest? 3.5 Ecological characteristics of components? (non-programmatic) 3.6 Ecological characteristics of components? (programmatic) 3.7 Where do components occur? 3.8 How to correlate components to ecosites? 3.9 How to QC the correlation between 3.10 Test section", " Chapter 3 Components The concept of map units and map unit components is essential to understand for ecological site work. Map units are associated with landforms, though this is not explicitly stated in the map unit section of the Soil Survey Manual. Examples of landforms that map units might be associated with in a mountain landscape could include, north-facing backslopes of mountains, ….. Map units are spatially explicit - they are delineated as polygons on a map. Often times, map units have multiple delineations. For example, the same map unit - let’s call it Map Unit #1 - can appear multiple times on your soil map. Despite having separate delineations, all of the delineations are the same map unit - Map Unit #1. Map units have one, or more, map unit components. Map unit components, or simply - components, partition map units into areas with different properties. Examples of properties that may differ include, family particle size class, depth to restriction, drainage class, surface fragments, and others. Typically, component within a map unit will not differ based on elevation or slope. Elevation and slope contribute towards the landform and therefore significant differences would justify creating a separate map unit. Components are not spatially explicit, there are not polygons on a map showing the spatial location of components. Components should be identifiable in the field, though. For example, if you know you are within a map unit (check to see if you are within the map unit polygon), you should be able to distinguish between the possible components of that map unit. For example, a map unit may have two components - Component A and Component B. Component A has higher surface fragments than Component B. Therefore, to determine if a specific location within your map unit of interest is Component A or B, you would examine the amount of surface fragments. Though components are not spatially explicit, a component percent is assigned. The component percent describes the percentage of the map unit that the component is expected to occupy. For example, a component percent of 40 would mean that 40% of the map unit is expected to be associated with that component. Given that map units have a defined acreage, you can determine the number of acres associated with each component by multiplying the map unit acreage times the component percent. If a map unit has a total acreage of 500,000 acres and the Component A has a component percent of 60, than there are 300,000 acres of Component A. A component should appear in all delineations of a map unit. If Component A and Component B are part of Map Unit #1, they should appear in all delineations. Technically, they should appear in the same proportions. For example, if Component A has a component percent of 60, 60% of the acreage of all map unit delineations should be Component A. In practice, this is often not the case. Components appear in different map unit delineations in different proportions. Just as the separate map unit delineations are the same map unit - Map Unit #1, the components appearing in each delineation are considered the same component. No matter how many delineations of Map Unit #1 there are, they are all Map Unit #1 every time Component A appears in each delineation, it is still Component A. There are several structures for naming map units in NASIS, including mukey, musym, muiid. A common way of identifying map units is using mukey. The common way of identifying component is coiid. This is unique identifier for components. Each component has a unique coiid. Ultimately, it is the coiid that an ecological site is correlated to. Components also have a component name. The component name can be a soil series or a higher soil taxonomic class, such as family. Component names are not unique to components. If multiple components are associated with the same soil series, than those components will all have the same component name. For example, if Component A from Map Unit #1 and a different component - Component Z from Map Unit #9 - are both associated with the soil series, Turney, than Component A and Component Z will both have the component name, Turney. Some areas of country require all components with the same component name to be correlated to the same ecological site. This would mean that Component A and Component Z must be correlated to the same ecological site. Component phases are a way of distinguishing that two components with the same component name differ in some condition. Various descriptors can be used to phase a component, such as cool, warm, steep - any modifier that describes how the component is different from other components with the same name. Often times, phases are used as justification for components with the same component name being correlated to different ecological sites. Ecological sites, are correlated to th Depending on the order of the soil survey, components may be associated with soil series or high taxa, such as family. are one of the core concepts in the NRCS ecological workflow. Ecosites are correlated to components. Components are part of Often times we will access component level data using a query and then the fetchNASIS function. One of the fetchNASIS arguments is duplicates. This argument helps to deal with the fact that components (coiids) can be associated with multiple legends. In the vast majority of cases, a component being associated with multiple legends is the result of a MLRA mapunit. An MLRA mapunit uses the same data mapunit across survey boundaries. MLRA mapunits are increasingly popular because they allow mapunits to span larger, environmentally contiguous areas, like MLRAs, rather than being restricted to political or administrative boundaries, like counties and soil survey areas. As a result, a component (coiid) can be associate with multiple legends. By default (duplicates = FALSE), fetchNASIS outputs a single instance for each component and does not include legend level information, such as areasymbol, mukey, muacres, etc. To include legend level information, you must duplicate (duplicates = TRUE) the components, or report each component multiple times if it exists in multiple legends. If duplicates = TRUE, components will be listed for every time they are used in a different legend. If a component is used in four legends, it will be listed four times. When components are duplicated, each instance is associated with a particular legend, therefore the specific legend information will be included. The full list of additional variables that will be include is: coiidcmb, muiid, lmapunitiid, mukey, musym, nationalmusym, muname, mukind, mutype, mustatus, muacres, farmlndcl, repdmu, areasymbol, areaname, ssastatus, cordate. 3.1 Identify components in MLRA? There are NASIS Queries that allow querying by MLRA. Unfortunately, this is not the best approach. See the section What mapunits are in an MLRA for an explanation of why. Spatial intersection of MLRA boundaries and mapunits is more reliable. Determine the mapunits in the MLRA using the Mapunits in MLRA tool Take the group of mapunits and enter them into Query &gt; MLRA09_Temple &gt; ARE/LMU/MU/DMU by Lmukey list. Run against National Database: Run against Local: Acquire the component names and component IDs using R: Load the soilDB package and fetch NASIS data library(soilDB) my.components.MLRA &lt;- fetchNASIS(from = &quot;components&quot;, duplicates = TRUE) Look at component names - the head() function shows just the first six records. Remove the head() function to see all the component names head(my.components.MLRA$compname) ## [1] &quot;Clay pits&quot; &quot;Quarry&quot; &quot;Pits&quot; &quot;Dams&quot; &quot;Water&quot; &quot;Dams&quot; Look at the component IDs head(site(my.components.MLRA)$coiid) ## [1] 1199623 658862 1201344 650195 650196 650195 3.2 Identify components in Soil Survey Area? Queries by Soil Survey Area are much more reliable than queries by MLRA. As previously mentioned, queries by MLRA are not ideal because the mapunit overlap tables are imperfectly populated. The Soil Survey area corresponds to the legend, and this means that components are reliably associated with Soil Survey Areas. Therefore, beginning with a query is the preferred approach: Run against National Run against Local Acquire component names and IDs using R. Load the soilDB package and fetch NASIS data library(soilDB) my.components.SSA &lt;- fetchNASIS(from = &quot;components&quot;, duplicates = TRUE) ## Warning: Horizon top depths contain NA! Check depth logic with ## aqp::checkHzDepthLogic() ## Warning: Horizon bottom depths contain NA! Check depth logic with ## aqp::checkHzDepthLogic() ## Warning in `hzidname&lt;-`(`*tmp*`, value = &quot;chiid&quot;): horizon ID name (chiid) not ## unique. unique ID not changed. Look at component names - the head() function shows just the first six records. Remove the head() function to see all the component names head(my.components.SSA$compname) ## [1] &quot;Water&quot; &quot;Rock outcrop&quot; &quot;Typic Cryorthents&quot; ## [4] &quot;Benchlake&quot; &quot;Rock outcrop&quot; &quot;McDermand&quot; Look at the component IDs head(my.components.SSA$coiid) ## [1] 650196 2405837 2405838 2405955 2405841 2776001 3.3 Existing component, ecosite correlations Perhaps we want to see what ecosite each component is correlated to. For this example, we will work with all the components in MLRA 18 using the Standard Dataset and packages. With the Standard Dataset loaded, let’s look at the correlations between component ID and ecosite ID. This script takes our components in MLRA 18, pulls out the site level data (allows us to ignore pedon data), and then selects only the columns for component ID and ecosite ID (there are lots of other columns you can choose from, tailor to your needs). Finally we look at just the head() of the comp.ecosite.correlations. If you want to see the full dataframe, remove head(). comp.ecosite.correlations &lt;- my.components.MLRA %&gt;% aqp::site() %&gt;% dplyr::select(coiid, ecosite_id) head(comp.ecosite.correlations) ## coiid ecosite_id ## 1 1199623 &lt;NA&gt; ## 2 658862 &lt;NA&gt; ## 3 1201344 &lt;NA&gt; ## 4 650195 &lt;NA&gt; ## 5 650196 &lt;NA&gt; ## 6 650195 &lt;NA&gt; 3.4 Components correlated to an ecosite of interest? Perhaps there is a specific ecosite we are interested in and we want to see what components are correlated to that ecosite. Let’s say the ecosite is R018XI202CA. We will start with the comp.ecosite.correlations dataframe that we created in the previous example. R018XI202CA &lt;- comp.ecosite.correlations %&gt;% filter(ecosite_id == &quot;F018XA202CA&quot;) head(R018XI202CA) # Again, remove head() to see the full list. ## coiid ecosite_id ## 1 1122909 F018XA202CA ## 2 1153767 F018XA202CA ## 3 1153765 F018XA202CA ## 4 1153766 F018XA202CA ## 5 1153763 F018XA202CA ## 6 627676 F018XA202CA 3.5 Ecological characteristics of components? (non-programmatic) One of the best ways to do this is a NASIS report: NASIS &gt; Reports &gt; MLRA02_Davis &gt; EXPORT - Ecological site concept data by MUKEY list v3. This report takes mapunit keys (MUKEY) as input. If you are interested in all the components in an MLRA, refer to What mapunits are in an MLRA?. If you are interested in a Soil Survey Area …… Run against National In the resulting output (html output in your browser), click anywhere, ctrl + a (select all), ctrl + c (copy) Open Excel, click in top left cell, ctrl + v (paste) Ctrl + a (select all), Insert &gt; Table Now you have a table with lots of ecological characteristics. You can use the column headers to filter in various ways. If you prefer to work in R, save this file as a .csv and read it into R. 3.6 Ecological characteristics of components? (programmatic) Load the Standard Dataset and packages. Let’s start off by removing miscellaneous areas and minor components. This is going to simplify things and remove some of the oddities that may exist in the data. Ecological sciences do not correlate to misc. areas or minor components, so it will not be a loss to us. nasis_selection &lt;- subset(my.components.MLRA, compkind != &quot;miscellaneous area&quot; &amp; majcompflag == &quot;1&quot;) Horizon level data Create data frame from the horizon level data. This script provides the flexibility to add characteristics of interest. If there are other horizon level data that you are interested in, you can add it following the same syntax shown below. To see what horizon level data is available, type ‘nasis_selection@horizons$’ into the console. Horizon level data is summarized into site level info. If you add other horizon level data, make sure it is summarized in a conceptually meaningful way. horizon_df &lt;- data.frame(texture = nasis_selection$texture, frag_vol = nasis_selection$fragvoltot_r, sand = nasis_selection$sandtotal_r, clay = nasis_selection$claytotal_r, sieve10 = nasis_selection$sieveno10_r, thickness = nasis_selection$hzdepb_r - nasis_selection$hzdept_r, rock_frag = nasis_selection$total_frags_pct, ph_l = nasis_selection$ph1to1h2o_l, ph_r = nasis_selection$ph1to1h2o_r, ph_h = nasis_selection$ph1to1h2o_h, awc_l = nasis_selection$awc_l, awc_r = nasis_selection$awc_r, awc_h = nasis_selection$awc_h, coiidcmb = nasis_selection$coiidcmb) %&gt;% left_join(site(nasis_selection) %&gt;% dplyr::select(coiidcmb, coiid)) %&gt;% select(-coiidcmb) %&gt;% dplyr::rename(component = coiid) ## Joining with `by = join_by(coiidcmb)` Separate the texture column horizon_df$texture_qualifier &lt;- horizon_df$texture %&gt;% stringr::str_extract(&quot;.*(?=-)&quot;) horizon_df$texture_only &lt;- horizon_df$texture %&gt;% stringr::str_extract(&quot;(?&lt;=-).*&quot;) horizon_df$texture_only &lt;- ifelse(is.na(horizon_df$texture_only), horizon_df$texture, horizon_df$texture_only) Working with texture: We have two goals for texture. One, we want to have a textural modifier where appropriate (i.e., CB, CBV, GR). Two, we want to have a texture (i.e., L, CL, SC). Ultimately, we want a single textural modifier and a single texture to represent the entire soil profile. We are starting off with textural modifiers and textures for each horizon, though. Therefore, we need to consider how to aggregate that data. Textural modifiers - For textural modifiers, we will choose the textural modifier from the thickest soil horizon and that textural modifier will be used as a value that represents the entire profile. Before doing that, we are going to change the depth of horizons that were not textured. For those horizons that were not textured, we are going to change the depth to 0.1 cm. This will prevent textural modifiers from being defined based on a horizon that was not textured. For example, a BR horizon is automatically assigned a depth of 25 cm. Depth of BR has limited ecological significance, and we do not want the texture of the soil profile to be determined by BR conditions. We are also specifically stating that texture is not equal to “BR” because several horizons that are BR have values of 0 for sand and clay when they should be NAs. horizon_df$thickness_modified &lt;- ifelse(is.na(horizon_df$clay), 0.1, ifelse(horizon_df$texture == &quot;BR&quot;, 0.1, horizon_df$thickness)) Now, we assign the textural modifier from the thickest horizon to the component. summarized_texture_qualifier &lt;- horizon_df %&gt;% dplyr::group_by(component, texture_qualifier) %&gt;% dplyr::summarize(combined_thickness = sum(thickness_modified)) %&gt;% dplyr::ungroup() %&gt;% dplyr::group_by(component) %&gt;% top_n(1, combined_thickness) %&gt;% ungroup() %&gt;% dplyr::select(-combined_thickness) Texture - Now, we are going to assign a texture to the entire profile. For texture, we have quantitative data (sand and clay percentages). This allows us to do a weighted average rather than just choosing the texture from the thickest horizon like we did for texture modifiers. First, we will remove horizons that do not have textures. We will also remove horizons labelled with texture as “BR” because some of those bedrock horizons have sand and clay percentages entered as zero rather than NA. Then, we group the horizons by the component id and calculate a weighted mean for clay/sand, pH, and rock frag using the horizon thickness as the weighting. weighted_texture &lt;- horizon_df %&gt;% dplyr::filter(!is.na(clay) &amp; !is.na(sand) &amp; texture != &quot;BR&quot;) %&gt;% dplyr::group_by(component) %&gt;% dplyr::summarise(clay_mean_texture = weighted.mean(clay, thickness_modified), sand_mean_texture = weighted.mean(sand, thickness_modified), ph_l_mean = weighted.mean(ph_l, thickness_modified), ph_r_mean = weighted.mean(ph_r, thickness_modified), ph_h_mean = weighted.mean(ph_h, thickness_modified), awc_l_sum = sum(awc_l * thickness_modified), awc_r_sum = sum(awc_r * thickness_modified), awc_h_sum = sum(awc_h * thickness_modified), rock_frag = weighted.mean(rock_frag, thickness_modified), depth_to_restr = sum(thickness_modified)) %&gt;% dplyr::mutate(textural_class = aqp::ssc_to_texcl(clay = clay_mean_texture, sand = sand_mean_texture)) Combine the texture qualifiers and the textures into a dataframe horizon_to_component_data &lt;- dplyr::left_join(summarized_texture_qualifier, weighted_texture) Component level data Here, we change gears and start assembling component level data. component_data &lt;- with(site(nasis_selection), data.frame( coiid = coiid, compname = compname, compkind = compkind, areasymbol = areasymbol, areaname = areaname, comppct_r = comppct_r, slope_l = slope_l, slope_r = slope_r, slope_h = slope_h, majcompflag = majcompflag, pmkind = pmkind, dmuiid = dmuiid, pmorigin = pmorigin, surf_frag = surface_total_frags_pct, elev_l = elev_l, elev_rv = elev_r, elev_h = elev_h, map_l = map_l, map_rv = map_r, map_h = map_h, maat_l = maat_l, maat_rv = maat_r, maat_h = maat_h, ffd_l = ffd_l, ffd_rv = ffd_r, ffd_h = ffd_h, aspectccwise = aspectccwise, aspectrep = aspectrep, aspectcwise = aspectcwise, landform = landform_string, taxtemp = taxtempregime, drainagecl = drainagecl, ecosite = ecosite_name, ecosite_id = ecosite_id, taxorder = taxorder, taxsuborder = taxsuborder ) ) Collect restriction data restriction_data &lt;- restrictions(nasis_selection) %&gt;% dplyr::select(coiid, reskind, resdept_l, resdept_r, resdept_h, reshard) %&gt;% subset(!grepl(&quot;noncemented&quot;, reshard)) %&gt;% dplyr::group_by(coiid) %&gt;% arrange(resdept_r) %&gt;% dplyr::slice(1) Merge component data and restriction data component_data_combined &lt;- left_join(component_data, restriction_data) ## Joining with `by = join_by(coiid)` Merge horizon data and component data all_data &lt;- horizon_to_component_data %&gt;% dplyr::rename(coiid = component) %&gt;% left_join(component_data_combined) %&gt;% dplyr::select(coiid, compname, ecosite, ecosite_id, landform, pmkind, pmorigin, taxtemp, textural_class, texture_qualifier, rock_frag, surf_frag, depth_to_restr, drainagecl, slope_l, slope_r, slope_h, ph_l_mean, ph_r_mean, ph_h_mean, elev_l, elev_rv, elev_h, map_l, map_rv, map_h, maat_l, maat_rv, maat_h, ffd_l, ffd_rv, ffd_h ,comppct_r, dmuiid, everything()) ## Warning in left_join(., component_data_combined): Each row in `x` is expected to match at most 1 row in `y`. ## ℹ Row 149 of `x` matches multiple rows. ## ℹ If multiple matches are expected, set `multiple = &quot;all&quot;` to ## silence this warning. Save as csv write.csv(all_data, &quot;C:/Users/Nathan.Roe/Downloads/my_ecosite_report.csv&quot;, row.names = FALSE) 3.7 Where do components occur? 3.8 How to correlate components to ecosites? 3.9 How to QC the correlation between 3.10 Test section "],["ecosites.html", "Chapter 4 Ecosites 4.1 What ecosites are active in an MLRA? 4.2 Range in characteristics of ecosites 4.3 Mapping ecological sites 4.4 Associated sites 4.5 Determine acreage of single ecological site 4.6 Determine acreage of multiple ecological sites 4.7 Accessing plot level vegetation data", " Chapter 4 Ecosites 4.1 What ecosites are active in an MLRA? Load the Standard Dataset and packages. Then, we simply need to call the ecosite IDs or ecosite names, depending on your preference. Remember, remove head() to see the full list. head(my.components.MLRA$ecosite_id) ## [1] NA NA NA NA NA NA head(my.components.MLRA$ecosite_name) ## [1] NA NA NA NA NA NA There are likely NAs (missing values) in the above list. This is because the above considers components are are minor and miscellaneous. We do not correlate ecosites to components that are minor and miscellaneous. It will likely be more useful to remove minor and miscellaneous componets: my.components.MLRA.reduced &lt;- my.components.MLRA %&gt;% aqp::site() %&gt;% filter(compkind != &quot;miscellaneous area&quot; &amp; majcompflag == &quot;1&quot;) head(my.components.MLRA.reduced$ecosite_id) ## [1] &quot;R017XE041CA&quot; &quot;R017XY901CA&quot; &quot;R017XY902CA&quot; &quot;R017XY903CA&quot; &quot;R017XY903CA&quot; ## [6] &quot;R017XY904CA&quot; head(my.components.MLRA.reduced$ecosite_name) ## [1] &quot;Fine Loamy 8-10\\&quot; P.Z.&quot; &quot;Clayey Basin Group&quot; ## [3] &quot;Duripan Vernal Pools&quot; &quot;Stream Channels and Floodplains&quot; ## [5] &quot;Stream Channels and Floodplains&quot; &quot;Subirrigated Deep Alluvial Fans&quot; We might also be interested to see how often different ecosites are used: table(my.components.MLRA.reduced$ecosite_id) %&gt;% as.data.frame() %&gt;% dplyr::rename(Ecosite = Var1) %&gt;% arrange(desc(Freq)) %&gt;% head() ## Ecosite Freq ## 1 R017XY902CA 418 ## 2 F022AW007CA 398 ## 3 R017XY905CA 305 ## 4 R017XY903CA 290 ## 5 R017XY904CA 225 ## 6 F018XC201CA 201 Interesting… the most used ecosites in MLRA18 are ecosite concepts from MLRAs 22a and 17. 4.2 Range in characteristics of ecosites I created a report that summarizes the characteristics of ecosites. It is organized based on the information that is supposed to be populated in EDIT. Here is a link to a sample report. I have established a methodology allowing you to create reports like the one linked for all of the ecosites in your MLRA within a few short steps. You can also produce the report for just one of your ecosites. For documentation on this methodology, click here. Click on the green ‘Code’ button and choose ‘Download ZIP’. Once you have downloaded to the location of your preference, you can right click &gt; Extract all. You can then open the read_me.docx file. Additionally, you can watch the following YouTube video: 4.3 Mapping ecological sites For this methodology, the ecological site is mapped in all map units containing a component correlated to the ecological site. The alternative would be to map the ecological site only in map units where the dominant component is correlated to the ecological site of interest. I am more interest in the full extent of the ecological site, so I am using the less restrictive of the two. Load the Standard Dataset and packages. Load a shapefile of your map unit boundaries (the MLRA boundaries cover the whole country, but you will have to change the map unit boundaries to your local map unit shapefile) mapunit_boundaries &lt;- sf::read_sf(&quot;C:/Users/Nathan.Roe/Documents/PES/gSSURGO_CA_2022.gdb&quot;, &quot;mupolygon&quot;) mlra_boundaries &lt;- sf::read_sf(&quot;C:/Users/Nathan.Roe/Documents/PES/MLRA_52_2022/MLRA_52_2022/MLRA_52.shp&quot;) What is your ecological site of interest? (change appropriate to your project) ecosite_of_interest &lt;- &quot;R018XE104CA&quot; What is your MLRA of interest? (change appropriate to your project) mlra_of_interest &lt;- 18 Reduce component data to those associated with ecosite of interest my.components.MLRA.reduced &lt;- aqp::site(my.components.MLRA) %&gt;% filter(ecosite_id == ecosite_of_interest) Reduce mapunits to those associated with ecosite of interest mapunit_boundaries_of_interest &lt;- mapunit_boundaries %&gt;% dplyr::filter(MUKEY %in% my.components.MLRA.reduced$muiid) %&gt;% sf::st_transform(&quot;+proj=longlat +datum=WGS84&quot;) Reduce MLRA boundary to MLRA of interest mlra_boundaries_reduced &lt;- mlra_boundaries %&gt;% dplyr::filter(MLRARSYM == mlra_of_interest) %&gt;% sf::st_transform(&quot;+proj=longlat +datum=WGS84&quot;) Select state of interest (change appropriate to your project, you could select multiple states too) ca &lt;- st_as_sf(maps::map(&quot;state&quot;, fill = TRUE, plot = FALSE)) %&gt;% dplyr::filter(ID == &quot;california&quot;) %&gt;% sf::st_transform(&quot;+proj=longlat +datum=WGS84&quot;) Plot map ggplot() + theme_minimal() + geom_sf(data = ca) + geom_sf(data = mlra_boundaries_reduced) + geom_sf(data = mapunit_boundaries_of_interest, col = &quot;hotpink&quot;, alpha = 0, size = 2) + ggtitle(paste0(&quot;Distribution of ecological site - &quot;, ecosite_of_interest)) 4.4 Associated sites Associated sites are ecological sites that occur in the same area of the landscape. The simplest way to think about this is ecological sites that are adjacent to your ecological site of interest. I am going to present a simple way of addressing this. We can determine what ecological sites occur in the same mapunit as your ecosite of interest. Looking at all the mapunits that your ecological site of interest occurs in, and tallying up all of the other ecological sites that are in shared mapunits, we can come to a metric of what other ecological sites tend to be near your ecological site of interest. In the future, I would like to make some improvements to this, so that it considers adjacent mapunits and considers the length of boundary between mapunits. Load the Standard Dataset and packages. Reduce data how you see fit. I am just going to remove miscellaneous areas, but you could choose additional criteria such as removing minor components. my.components.MLRA.reduced &lt;- my.components.MLRA@site |&gt; dplyr::filter(compkind != &quot;miscellaneous area&quot;) Calculate the acreage associated with each component my.components.MLRA.reduced$comp_acres &lt;- (my.components.MLRA.reduced$muacres * my.components.MLRA.reduced$comppct_r)/100 Create empty list for upcoming for loop associated_ecosites &lt;- list() Create for loop to calculate the acreage of ecosites that occur in the same mapunits as your ecosite of interest. The results will be in a list. for(i in my.components.MLRA.reduced$ecosite_id |&gt; unique()){ associated_ecosites[[i]] &lt;- my.components.MLRA.reduced |&gt; dplyr::filter(mukey %in% (my.components.MLRA.reduced |&gt; dplyr::filter(ecosite_id == i) |&gt; dplyr::pull(mukey))) |&gt; dplyr::group_by(ecosite_id) |&gt; dplyr::summarise(acres = sum(comp_acres)) |&gt; dplyr::filter(ecosite_id != i) |&gt; arrange(dplyr::desc(acres)) } Let’s take a look at an example associated_ecosites$F018XA202CA ## # A tibble: 3 × 2 ## ecosite_id acres ## &lt;chr&gt; &lt;dbl&gt; ## 1 R018XA103CA 14813. ## 2 R018XA104CA 8784. ## 3 R015XF008CA 1657 4.5 Determine acreage of single ecological site My office leader recently asked me how many acres a particular ecological site occupies because she was entering it as a project in NASIS and needed the associated acres. You might need to do something similar for a NASIS project, a tech team meeting, or to improve your own understanding of how prevalent an ecological site is. Load the Standard Dataset and packages. First, let’s say we have a particular ecosite of interest - “R018XI105CA” my_ecosite &lt;- aqp::site(my.components.MLRA) %&gt;% dplyr::filter(ecosite_id == &quot;R018XI105CA&quot;) Now let’s look at the components correlated to our ecosite of interest, the component percent (percent of mapunit represented by component), the mapunit acres, and calculate the acres associated with each component by multiplying component percent and mapunit acres. my_ecosite_compacres &lt;- my_ecosite %&gt;% select(ecosite_id, coiid, comppct_r, muacres) %&gt;% mutate(comp_acreage = (comppct_r/100)*muacres) head(my_ecosite_compacres) ## ecosite_id coiid comppct_r muacres comp_acreage ## 1 R018XI105CA 2516892 25 5717 1429.25 ## 2 R018XI105CA 2029027 10 34449 3444.90 ## 3 R018XI105CA 2500528 17 34449 5856.33 ## 4 R018XI105CA 1842728 25 7447 1861.75 ## 5 R018XI105CA 2029025 10 7447 744.70 ## 6 R018XI105CA 2482828 15 22906 3435.90 Then, we just need to sum the comp_acreage sum(my_ecosite_compacres$comp_acreage) ## [1] 85585.38 4.6 Determine acreage of multiple ecological sites Let’s look at how we would efficiently calculate the acreage of all the ecosites in your MLRA. First, we will restrict the ecosites of interest to only those associate with MLRA 18. MLRA18_ecosites &lt;- my.components.MLRA$ecosite_id %&gt;% str_subset(pattern = &quot;18X&quot;) %&gt;% unique() Now we can run a for loop that goes through each ecological site, calculates the acreage, and puts them all in a data frame ecosite_list &lt;- list() for(i in MLRA18_ecosites){ ecosite_list[[i]] &lt;- aqp::site(my.components.MLRA) %&gt;% dplyr::filter(ecosite_id == i) %&gt;% select(ecosite_id, coiid, comppct_r, muacres) %&gt;% mutate(comp_acreage = (comppct_r/100)*muacres) %&gt;% summarise(Ecosite = first(ecosite_id), Acreage = sum(comp_acreage)) } MLRA18_ecosite_acreage &lt;- do.call(rbind, ecosite_list) %&gt;% remove_rownames() head(MLRA18_ecosite_acreage) ## Ecosite Acreage ## 1 R018XI163CA 251072.59 ## 2 R018XI164CA 38683.76 ## 3 F018XI200CA 406409.32 ## 4 R018XA102CA 8555.35 ## 5 F018XA201CA 32945.32 ## 6 F018XI201CA 364947.53 4.7 Accessing plot level vegetation data This requires a bit of Querying magic. The Query that we want is MLRA13_Wasilla &gt; ‘Pedon/Site/Vegetation Plot by area overlap type and areasym’. The description for this Query gives the necessary details. NATIONAL: Have to run this twice against the national in order to get sites, pedons, and vegetation plot. First, set target table to PEDON. Second, set target tablet to VEGETATION PLOT. LOCAL: Set target tablest to PEDON, SITE, and VEGETATION PLOT. Run against National - Pedon Run against National - Vegetation plot Run against Local veg_data &lt;- fetchVegdata(SS = TRUE) I will return to this to provide some tools for dealing with the actual veg data. test &lt;- data.frame(UserSiteID = veg_data$vegplot$site_id, DataOrigin = veg_data$vegplot$vegdataorigin) table(test$DataOrigin) ## ## site existing veg table spreadsheet form ## 470 880 "],["species.html", "Chapter 5 Species 5.1 Mapping the location of species", " Chapter 5 Species 5.1 Mapping the location of species Let’s take a look at the location of species. To do this we will query plot level NASIS data using the query outlined in Accessing plot level vegetation data. Once you have queried, you can filter your dataset for any species of interest. I am going to search for a genus - Artemisia (sagebrush). Ultimately, we will produce a map that shows the distribution of all the species of Artemisia. veg_data &lt;- fetchVegdata(dsn = &quot;C:/Users/Nathan.Roe/Documents/SEKI/CA792_veg.sqlite&quot;, SS = FALSE) ## NOTE: some records are missing surface fragment cover artemesia_df &lt;- veg_data$vegplotspecies %&gt;% filter(plantsciname %in% str_subset(veg_data$vegplotspecies$plantsciname, &quot;Artemisia&quot;)) %&gt;% select(siteiid, plantsciname) Query for Artemisia and create a spatial dataframe with coordinates artemesia_df &lt;- veg_data$vegplotspecies %&gt;% filter(plantsciname %in% str_subset(veg_data$vegplotspecies$plantsciname, &quot;Artemisia&quot;)) %&gt;% select(siteiid, plantsciname) artemesia_location &lt;- veg_data$vegplotlocation %&gt;% dplyr::filter(siteiid %in% artemesia_df$siteiid) %&gt;% select(siteiid, utmzone, utmeasting, utmnorthing) %&gt;% dplyr::left_join(artemesia_df) %&gt;% st_as_sf(coords = c(&#39;utmeasting&#39;, &#39;utmnorthing&#39;), crs = st_crs(32611)) ## Joining with `by = join_by(siteiid)` ## Warning in dplyr::left_join(., artemesia_df): Each row in `x` is expected to match at most 1 row in `y`. ## ℹ Row 1 of `x` matches multiple rows. ## ℹ If multiple matches are expected, set `multiple = &quot;all&quot;` to ## silence this warning. Create a list of dataframes based on the different veg_data &lt;- fetchVegdata(dsn = &quot;C:/Users/Nathan.Roe/Documents/SEKI/CA792_veg.sqlite&quot;, SS = FALSE) ## NOTE: some records are missing surface fragment cover artemesia_df &lt;- veg_data$vegplotspecies %&gt;% filter(plantsciname %in% str_subset(veg_data$vegplotspecies$plantsciname, &quot;Artemisia&quot;)) %&gt;% select(siteiid, plantsciname) artemesia_location &lt;- veg_data$vegplotlocation %&gt;% dplyr::filter(siteiid %in% artemesia_df$siteiid) %&gt;% select(siteiid, utmzone, utmeasting, utmnorthing) %&gt;% dplyr::left_join(artemesia_df) %&gt;% st_as_sf(coords = c(&#39;utmeasting&#39;, &#39;utmnorthing&#39;), crs = st_crs(32611)) ## Joining with `by = join_by(siteiid)` ## Warning in dplyr::left_join(., artemesia_df): Each row in `x` is expected to match at most 1 row in `y`. ## ℹ Row 1 of `x` matches multiple rows. ## ℹ If multiple matches are expected, set `multiple = &quot;all&quot;` to ## silence this warning. artemesia_location_split &lt;- split(artemesia_location, artemesia_location$plantsciname) my_colors &lt;- RColorBrewer::brewer.pal(n = length(artemesia_location_split), name = &#39;Set1&#39;) mapview::mapView(artemesia_location_split, col.regions = my_colors) It can be really useful to create a stored version of your selected set. That way, if you are frequently changing between different different selected sets, you do not have to clear your selected set and run a new query. This can be done by saving your selected set as an SQlite database. This allows you to call the saved SQlite database in SoilDB functions. Let’s look at how we can create a stored SQlite database. soilDB::createStaticNASIS(SS = TRUE, tables = soilDB::get_NASIS_table_name_by_purpose(c(&quot;area&quot;, &quot;legend&quot;, &quot;mapunit&quot;, &quot;datamapunit&quot;, &quot;component&quot;, &quot;metadata&quot;, &quot;lookup&quot;, &quot;nasis&quot;)), output_path = &quot;C:/Users/Nathan.Roe/Documents/SEKI/CA792_veg.sqlite&quot;) Note: The tables listed in the get_NASIS_table_name_by_purpose argument should cover the majority of situations. If you run into an issue, though, soilDB will likely name a specific table that is missing. If that happens, you will have to add the table to the character vector. Once you have stored your SQlite database, you can call it using the soilDB functions. The default argument in fetchNASIS() and other SoilDB functions is SS = TRUE. We are going to change that to false and identify the location of the SQlite database in the dsn argument. my.components.MLRA &lt;- fetchNASIS(from = &quot;components&quot;, duplicates = T, dsn = &quot;C:/Users/Nathan.Roe/Documents/SEKI/CA792_veg.sqlite&quot;, SS = FALSE) This can be extremely useful when you have multiple selected sets that you are working with. "],["nasis.html", "Chapter 6 NASIS 6.1 Creating a Static NASIS database", " Chapter 6 NASIS 6.1 Creating a Static NASIS database It can be really useful to create a stored version of your selected set. That way, if you are frequently changing between different different selected sets, you do not have to clear your selected set and run a new query. This can be done by saving your selected set as an SQlite database. This allows you to call the saved SQlite database in SoilDB functions. Let’s look at how we can create a stored SQlite database. soilDB::createStaticNASIS(SS = TRUE, tables = soilDB::get_NASIS_table_name_by_purpose(c(&quot;area&quot;, &quot;legend&quot;, &quot;mapunit&quot;, &quot;datamapunit&quot;, &quot;component&quot;, &quot;metadata&quot;, &quot;lookup&quot;, &quot;nasis&quot;)), output_path = &quot;C:/Users/Nathan.Roe/Documents/SEKI/vegplotdata.sqlite&quot;) Note: The tables listed in the get_NASIS_table_name_by_purpose argument should cover the majority of situations. If you run into an issue, though, soilDB will likely name a specific table that is missing. If that happens, you will have to add the table to the character vector. Once you have stored your SQlite database, you can call it using the soilDB functions. The default argument in fetchNASIS() and other SoilDB functions is SS = TRUE. We are going to change that to false and identify the location of the SQlite database in the dsn argument. my.components.MLRA &lt;- fetchNASIS(from = &quot;components&quot;, duplicates = T, dsn = &quot;C:/Users/Nathan.Roe/Documents/SEKI/vegplotdata.sqlite&quot;, SS = FALSE) This can be extremely useful when you have multiple selected sets that you are working with. "],["package-buildingmaintaining-tips.html", "Chapter 7 Package building/maintaining tips 7.1 Package building/maintaining tips", " Chapter 7 Package building/maintaining tips 7.1 Package building/maintaining tips This section has helpful reminders for building and maintaining R packages. Update package documentation # devtools::document() Add package # use_package() Add function from package. Adding a function from a package instead of the whole package keeps things lighter weight. If you want to just add a function, use the script below and put it in your function.R file where you use their function. # @importFrom package-name object1 object2 objectn Make a package documentation file # usethis::use_package_doc() Check out this link for more details - https://devtools.r-lib.org/ "],["random-tools.html", "Chapter 8 Random tools 8.1 Organizing scanned data", " Chapter 8 Random tools 8.1 Organizing scanned data Digitizing and organizing datasheets can be tedious. The following workflow automates this process, removing the need to create/name folders, name files, scan documents individually (or manually separate), and sort files into the appropriate folder. Instead, you can use the office scanner and scan all of your datasheets at once into a single pdf file. Then, using R we will separate that file into individual pdfs, one pdf for each site. Each pdf will be named using the site id and put in a folder using the same site id. Let’s go over the steps - Organize your paper datasheets in numerical order Scan your paper datasheets using the office scanner. You should be able to feed all of the datasheets in at once. The result is a single pdf file with all of your sites. Determine the site numbers. This step requires either extracting the site numbers from a GPS device, NASIS, or some other source OR typing the site numbers manually. Typing the site numbers manually would look like this: my_site_number &lt;- c(401, 402, 403, 404, 405) Depending on what you have available and your skillset (willing to use soilDB to pull sites/pedons under your name in NASIS, etc.), you may have to enter this manually. This will be the only manual portion though. Install the ecositer R package remotes::install_github(&quot;natearoe/ecositer&quot;, dependencies = FALSE) Look at the help file for the scanned_data_organizer() function in R ?ecositer::scanned_data_organizer() Run scanned data_organizer(). Remember that your paths need to have forward slashes, not back slashes. That’ll be a show stopper. I do find and replace all. Here is an example of running scanned_data_organizer(): ecositer::scanned_data_organizer(scanned_data_path = &quot;S:/NRCS/XEROX SCANS/DOC057.pdf&quot;, directory = &quot;C:/Users/Nathan.Roe/Documents/Alaska2023/Willow_project&quot;, year_state_fips = &quot;2023AK185&quot;, site_number = my_site_number) That’s it! You now have a folder for each site that contains a pdf of that site’s datasheet. There is also an all_sites folder containing all of the site pdfs together in one location. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
