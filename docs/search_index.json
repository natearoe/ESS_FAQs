[["index.html", "NRCS Ecologist FAQs Chapter 1 Introduction 1.1 Overview 1.2 ODBC Connection 1.3 Standard dataset/packages", " NRCS Ecologist FAQs Nathan Roe - nateroe@gmail.com 2025-03-26 Chapter 1 Introduction This documents outlines common methodologies used by NRCS Ecologists. It is intended to be an educational resource and to develop best practice standards. This is intended to be a living document. If you have recommendations for best practices or additional practices that should be added, please let me know! 1.1 Overview This document is divided into 4 sections: mapunits, components, plots, and ecosites. Within those sections are commonly used methodologies relating to the section concept. For example, within the components section are methodologies relating to the use of components (i.e., What are the ecological characteristics of components?). Much of this methodology relies on a combination of NASIS and R. It is my objective to make the R examples clear enough that someone with minimal to no experience with R can reproduce these examples. 1.2 ODBC Connection As mentioned, these methodologies frequently utilize R and NASIS. To accomplish this, you will need to have R installed and establish an ODBC connection to NASIS. This is outlined in detail by the NRCS Stats for Soil Survey pre-course assignment. 1.3 Standard dataset/packages For many of the examples in this document, we will be using the same dataset and packages. I will refer to this as the Standard Dataset. I will provide links back to this section where the Standard Dataset is used. Load standard packages library(soilDB) library(dplyr) library(aqp) library(sf) library(stringr) library(ggplot2) library(maps) Step 1. Determine the mapunits of interest using the Mapunit in MLRA tool for MLRA 18 with a 15% Membership. This tool is discussed in detail in What mapunits are in an MLRA?. Step 2. Take the group of mapunits and enter them into Query &gt; NSSC Pangaea &gt; Area/Legend/Mapunit/DMU by record ID - LMAPUNITIID list. Run against National Database: Run against Local: Step 3. Fetch NASIS data my.components.MLRA &lt;- fetchNASIS(from = &quot;components&quot;, duplicates = TRUE) Note on the duplicates = TRUE argument: fetchNASIS(from = \"components\") can access two hierarchical levels of data. The higher hierarchical level data is mapunit/soil survey area data. The lower hierarchical level data is component level data. By default, fetchNASIS(from = \"components\") accesses data at the component level. At times, we want to access data at a higher level (mapunit/soil survey area). When we want to access higher level data, the component level data must be nested within the higher level data. If there is a multiple:1 relationship between the higher level data and the component level data, duplication occurs. The multiple:1 relationship between higher level data and the component level data occurs because of MLRA mapunits - mapunits that occur across soil survey areas. With MLRA mapunits, components can be used in multiple mapunits/soil survey areas. The take-home message is that you need to use the duplicates = TRUE to access mapunit/soil survey area data. This argument will cause duplication of component level data for MLRA mapunits where the component is used in multiple mapunits/soil survey areas. This is will provide you with the same data that I am using, if you want to following along exactly. You will likely find it to be of greater utility to use map units relevant to you, though. You can also use different Queries that do not take map units as input. Many Queries will return the same fields as the Query in Step 2 (i.e., the Query, NSSC Pangaea &gt; Area/Legend/Mapunit/DMU by record ID - COIID will also work with most of the methodologies outlined if you prefer to query by Component ID). NASIS Queries do vary from each other, though, so it depends on the intracies of the Query. "],["mapunits.html", "Chapter 2 Mapunits 2.1 What mapunits are in an MLRA? 2.2 What mapunits are in a Soil Survey Area? 2.3 Mapping mapunits", " Chapter 2 Mapunits This section deals with mapunits. Mapunits have limited application for ecological work because they are broad concepts. Mapunits frequently contain multiple components, each occurring on different parts of the landscape and having different soil properties. Ecosites are correlated to components rather than mapunits because of the variability of mapunits. It should be noted that mapunits are spatially delineated, though, whereas components are not. Therefore, an attempt to map ecosites would rely heavily on mapunit delineations. An example of this can be seen on Web Soil Survey. Web Soil Survey can be used to map ecosites. These maps use mapunit delineations and show the ecosites that are correlated to the dominant component in that mapunit. For the purpose of this document, mapunits are primarily used as intermediate steps in different methodologies. For example, some NASIS Reports are particularly useful and require mapunits as input. Therefore, determining what mapunits are in your area of interest is helpful. The NRCS has four soil mapping products: SSURGO, gSSURGO, STATSGO, and gNATSGO. SSURGO is the most detailed product but is not available in all areas of the country. The resolution of SSURGO data ranges from 1:12,0000 to 1:63,360. gSSURGO is a gridded (rasterized) version of SSURGO - hence the “g” prefix. It covers the same areas as SSURGO but is gridded at a 10-meter cell size. STATSGO is a less detailed product but is available across all parts of the US. The resolution is 1:250,0000 in the continental US, Hawaii, Puerto Rico and the Virgin Islands. In Alaska, the resolution is 1:1,000,000. gNATSGO is a gridded combination of SSURGO and STATSGO. gNATSGO is primarily SSURGO data, but where SSURGO is unavailable, STATSGO is used to fill the gaps. The state-wide geodatabases are 10-meter cell sizes and the CONUS database is a 30-meter cell size. Data mapunits are the internal structure of mapunits. Data mapunits contain the mapunit component data as well as some information about the data mapunit itself. Over time, changes are sometimes made to data mapunits. Examples include adding a mapunit component to a mapunit, changing the particle size percentages of a mapunit component, or as a result of mapunits being renamed and aggregated as a result of transitioning into MLRA mapunits. When changes are made to a data mapunit, a new data mapunit is created. This new data mapunit becomes the representative data mapunit and the old data mapunit becomes a non-representative data mapunit. By doing this, a historical record of data mapunits is created, that way past versions are not lost. For ecological site work, we are almost always interested in working with representative data mapunits because they are the most up-to-date data available. 2.1 What mapunits are in an MLRA? If your MLRA uses primarily SSURGO data, the Mapunit in MLRA tool is the best option. It allow you to simply enter your MLRA of interest and define what percent of the total mapunit acreage must be within your MLRA for the mapunit to be considered a member of your MLRA of interest. Note that this tool will make two groups of mapunits if there are more than 2,100 mapunits. This happens because most NASIS queries do not allow for more than 2,100 mapunits to be included in a query. Why not use a NASIS Query that queries components by MLRA, like NASIS &gt; Queries &gt; NSSC Pangaea &gt; Area/Legend/Mapunit/DMU by MLRA? Unfortunately, this is not the most reliable way to determine what mapunits are in an MLRA. Mapunits are assigned to an MLRA via the mapunit area overlap table. These tables are not perfectly populated. Some mapunits are not assigned to an MLRA and others could be assigned to multiple MLRAs. For this reason, using a spatial intersection, as is done in the ‘Mapunit in MLRA tool’ is the preferred approach. Components are assigned from the same mapunit area overlap tables and therefore suffer from imperfect population of mapunit overlap tables also. Components 2.2 What mapunits are in a Soil Survey Area? Queries by Soil Survey Area are much more reliable than queries by MLRA. As previously mentioned, queries by MLRA are not ideal because the mapunit overlap tables are imperfectly populated. The Soil Survey area corresponds to the legend, and this means that components are reliably associated with Soil Survey Areas. Therefore, let’s use the following: NASIS &gt; Query &gt; NSSC Pangaea &gt; Area/Legend/Mapunit/DMU/Pedon/Site/ by areasymbol. Run against National Run against Local Acquire component names and IDs using R. Load the soilDB package and fetch NASIS data library(soilDB) my.mapunits.MLRA &lt;- fetchNASIS(from = &quot;components&quot;, duplicates = T) Look at the mapunits - the head() function shows just the first six records. Remove the head() function to see all the component names my.mapunits.MLRA$muname[1] ## [1] &quot;Goldwall-Toomes-Rock outcrop complex, 1 to 8 percent slopes&quot; Look at the mapunit keys my.mapunits.MLRA$mukey[1] ## [1] 1865918 2.3 Mapping mapunits Using Soil Web and R. "],["components.html", "Chapter 3 Components 3.1 Identify components in MLRA? 3.2 Identify components in Soil Survey Area? 3.3 Existing component, ecosite correlations 3.4 Components correlated to an ecosite of interest? 3.5 Ecological characteristics of components? (non-programmatic) 3.6 Ecological characteristics of components? (programmatic) 3.7 Where do components occur? 3.8 How to correlate components to ecosites? 3.9 How to QC the correlation between 3.10 Test section", " Chapter 3 Components The concept of map units and map unit components is essential to understand for ecological site work. Map units are associated with landforms, though this is not explicitly stated in the map unit section of the Soil Survey Manual. Examples of landforms that map units might be associated with in a mountain landscape could include, north-facing backslopes of mountains, ….. Map units are spatially explicit - they are delineated as polygons on a map. Often times, map units have multiple delineations. For example, the same map unit - let’s call it Map Unit #1 - can appear multiple times on your soil map. Despite having separate delineations, all of the delineations are the same map unit - Map Unit #1. Map units have one, or more, map unit components. Map unit components, or simply - components, partition map units into areas with different properties. Examples of properties that may differ include, family particle size class, depth to restriction, drainage class, surface fragments, and others. Typically, component within a map unit will not differ based on elevation or slope. Elevation and slope contribute towards the landform and therefore significant differences would justify creating a separate map unit. Components are not spatially explicit, there are not polygons on a map showing the spatial location of components. Components should be identifiable in the field, though. For example, if you know you are within a map unit (check to see if you are within the map unit polygon), you should be able to distinguish between the possible components of that map unit. For example, a map unit may have two components - Component A and Component B. Component A has higher surface fragments than Component B. Therefore, to determine if a specific location within your map unit of interest is Component A or B, you would examine the amount of surface fragments. Though components are not spatially explicit, a component percent is assigned. The component percent describes the percentage of the map unit that the component is expected to occupy. For example, a component percent of 40 would mean that 40% of the map unit is expected to be associated with that component. Given that map units have a defined acreage, you can determine the number of acres associated with each component by multiplying the map unit acreage times the component percent. If a map unit has a total acreage of 500,000 acres and the Component A has a component percent of 60, than there are 300,000 acres of Component A. A component should appear in all delineations of a map unit. If Component A and Component B are part of Map Unit #1, they should appear in all delineations. Technically, they should appear in the same proportions. For example, if Component A has a component percent of 60, 60% of the acreage of all map unit delineations should be Component A. In practice, this is often not the case. Components appear in different map unit delineations in different proportions. Just as the separate map unit delineations are the same map unit - Map Unit #1, the components appearing in each delineation are considered the same component. No matter how many delineations of Map Unit #1 there are, they are all Map Unit #1 every time Component A appears in each delineation, it is still Component A. There are several structures for naming map units in NASIS, including mukey, musym, muiid. A common way of identifying map units is using mukey. The common way of identifying component is coiid. This is unique identifier for components. Each component has a unique coiid. Ultimately, it is the coiid that an ecological site is correlated to. Components also have a component name. The component name can be a soil series or a higher soil taxonomic class, such as family. Component names are not unique to components. If multiple components are associated with the same soil series, than those components will all have the same component name. For example, if Component A from Map Unit #1 and a different component - Component Z from Map Unit #9 - are both associated with the soil series, Turney, than Component A and Component Z will both have the component name, Turney. Some areas of country require all components with the same component name to be correlated to the same ecological site. This would mean that Component A and Component Z must be correlated to the same ecological site. Component phases are a way of distinguishing that two components with the same component name differ in some condition. Various descriptors can be used to phase a component, such as cool, warm, steep - any modifier that describes how the component is different from other components with the same name. Often times, phases are used as justification for components with the same component name being correlated to different ecological sites. Ecological sites, are correlated to th Depending on the order of the soil survey, components may be associated with soil series or high taxa, such as family. are one of the core concepts in the NRCS ecological workflow. Ecosites are correlated to components. Components are part of Often times we will access component level data using a query and then the fetchNASIS function. One of the fetchNASIS arguments is duplicates. This argument helps to deal with the fact that components (coiids) can be associated with multiple legends. In the vast majority of cases, a component being associated with multiple legends is the result of a MLRA mapunit. An MLRA mapunit uses the same data mapunit across survey boundaries. MLRA mapunits are increasingly popular because they allow mapunits to span larger, environmentally contiguous areas, like MLRAs, rather than being restricted to political or administrative boundaries, like counties and soil survey areas. As a result, a component (coiid) can be associate with multiple legends. By default (duplicates = FALSE), fetchNASIS outputs a single instance for each component and does not include legend level information, such as areasymbol, mukey, muacres, etc. To include legend level information, you must duplicate (duplicates = TRUE) the components, or report each component multiple times if it exists in multiple legends. If duplicates = TRUE, components will be listed for every time they are used in a different legend. If a component is used in four legends, it will be listed four times. When components are duplicated, each instance is associated with a particular legend, therefore the specific legend information will be included. The full list of additional variables that will be include is: coiidcmb, muiid, lmapunitiid, mukey, musym, nationalmusym, muname, mukind, mutype, mustatus, muacres, farmlndcl, repdmu, areasymbol, areaname, ssastatus, cordate. 3.1 Identify components in MLRA? There are NASIS Queries that allow querying by MLRA. Unfortunately, this is not the best approach. See the section What mapunits are in an MLRA for an explanation of why. Spatial intersection of MLRA boundaries and mapunits is more reliable. Determine the mapunits in the MLRA using the Mapunits in MLRA tool Take the group of mapunits and enter them into Query &gt; MLRA09_Temple &gt; ARE/LMU/MU/DMU by Lmukey list. Run against National Database: Run against Local: Acquire the component names and component IDs using R: Load the soilDB package and fetch NASIS data library(soilDB) my.components.MLRA &lt;- fetchNASIS(from = &quot;components&quot;, duplicates = TRUE) Look at component names - the head() function shows just the first six records. Remove the head() function to see all the component names head(my.components.MLRA$compname) ## [1] &quot;Ultic Argixerolls&quot; &quot;Rock outcrop&quot; &quot;Toomes&quot; ## [4] &quot;Goldwall&quot; &quot;Aquic Haploxeralfs&quot; &quot;Loafercreek&quot; Look at the component IDs head(site(my.components.MLRA)$coiid) ## [1] 1685667 1685668 1778537 2250146 2250147 1844294 3.2 Identify components in Soil Survey Area? Queries by Soil Survey Area are much more reliable than queries by MLRA. As previously mentioned, queries by MLRA are not ideal because the mapunit overlap tables are imperfectly populated. The Soil Survey area corresponds to the legend, and this means that components are reliably associated with Soil Survey Areas. Therefore, beginning with a query is the preferred approach: Run against National Run against Local Acquire component names and IDs using R. Load the soilDB package and fetch NASIS data library(soilDB) my.components.SSA &lt;- fetchNASIS(from = &quot;components&quot;, duplicates = TRUE) Look at component names - the head() function shows just the first six records. Remove the head() function to see all the component names head(my.components.SSA$compname) ## [1] &quot;Ultic Argixerolls&quot; &quot;Rock outcrop&quot; &quot;Toomes&quot; ## [4] &quot;Goldwall&quot; &quot;Aquic Haploxeralfs&quot; &quot;Loafercreek&quot; Look at the component IDs head(my.components.SSA$coiid) ## [1] 1685667 1685668 1778537 2250146 2250147 1844294 3.3 Existing component, ecosite correlations Perhaps we want to see what ecosite each component is correlated to. For this example, we will work with all the components in MLRA 18 using the Standard Dataset and packages. With the Standard Dataset loaded, let’s look at the correlations between component ID and ecosite ID. This script takes our components in MLRA 18, pulls out the site level data (allows us to ignore pedon data), and then selects only the columns for component ID and ecosite ID (there are lots of other columns you can choose from, tailor to your needs). Finally we look at just the head() of the comp.ecosite.correlations. If you want to see the full dataframe, remove head(). comp.ecosite.correlations &lt;- my.components.MLRA %&gt;% aqp::site() %&gt;% dplyr::select(coiid, ecositeid) head(comp.ecosite.correlations) ## coiid ecositeid ## 1 1685667 F018XI207CA ## 2 1685668 &lt;NA&gt; ## 3 1778537 R018XI101CA ## 4 2250146 R018XI101CA ## 5 2250147 R018XI101CA ## 6 1844294 F018XI201CA 3.4 Components correlated to an ecosite of interest? Perhaps there is a specific ecosite we are interested in and we want to see what components are correlated to that ecosite. Let’s say the ecosite is R018XI201CA. We will start with the comp.ecosite.correlations dataframe that we created in the previous example. R018XI202CA &lt;- comp.ecosite.correlations %&gt;% filter(ecositeid == &quot;F018XA201CA&quot;) head(R018XI202CA) # Again, remove head() to see the full list. ## [1] coiid ecositeid ## &lt;0 rows&gt; (or 0-length row.names) 3.5 Ecological characteristics of components? (non-programmatic) One of the best ways to do this is a NASIS report: NASIS &gt; Reports &gt; MLRA02_Davis &gt; EXPORT - Ecological site concept data by MUKEY list v3. This report takes mapunit keys (MUKEY) as input. If you are interested in all the components in an MLRA, refer to What mapunits are in an MLRA?. If you are interested in a Soil Survey Area …… Run against National In the resulting output (html output in your browser), click anywhere, ctrl + a (select all), ctrl + c (copy) Open Excel, click in top left cell, ctrl + v (paste) Ctrl + a (select all), Insert &gt; Table Now you have a table with lots of ecological characteristics. You can use the column headers to filter in various ways. If you prefer to work in R, save this file as a .csv and read it into R. 3.6 Ecological characteristics of components? (programmatic) Load the Standard Dataset and packages. Let’s start off by removing miscellaneous areas and minor components. This is going to simplify things and remove some of the oddities that may exist in the data. Ecological sciences do not correlate to misc. areas or minor components, so it will not be a loss to us. nasis_selection &lt;- subset(my.components.MLRA, compkind != &quot;miscellaneous area&quot; &amp; majcompflag == &quot;1&quot;) Horizon level data Create data frame from the horizon level data. This script provides the flexibility to add characteristics of interest. If there are other horizon level data that you are interested in, you can add it following the same syntax shown below. To see what horizon level data is available, type ‘nasis_selection@horizons$’ into the console. Horizon level data is summarized into site level info. If you add other horizon level data, make sure it is summarized in a conceptually meaningful way. horizon_df &lt;- data.frame(texture = nasis_selection$texture, frag_vol = nasis_selection$fragvoltot_r, sand = nasis_selection$sandtotal_r, clay = nasis_selection$claytotal_r, sieve10 = nasis_selection$sieveno10_r, thickness = nasis_selection$hzdepb_r - nasis_selection$hzdept_r, rock_frag = nasis_selection$total_frags_pct, ph_l = nasis_selection$ph1to1h2o_l, ph_r = nasis_selection$ph1to1h2o_r, ph_h = nasis_selection$ph1to1h2o_h, awc_l = nasis_selection$awc_l, awc_r = nasis_selection$awc_r, awc_h = nasis_selection$awc_h, coiidcmb = nasis_selection$coiidcmb) %&gt;% left_join(site(nasis_selection) %&gt;% dplyr::select(coiidcmb, coiid)) %&gt;% select(-coiidcmb) %&gt;% dplyr::rename(component = coiid) ## Joining with `by = join_by(coiidcmb)` Separate the texture column horizon_df$texture_qualifier &lt;- horizon_df$texture %&gt;% stringr::str_extract(&quot;.*(?=-)&quot;) horizon_df$texture_only &lt;- horizon_df$texture %&gt;% stringr::str_extract(&quot;(?&lt;=-).*&quot;) horizon_df$texture_only &lt;- ifelse(is.na(horizon_df$texture_only), horizon_df$texture, horizon_df$texture_only) Working with texture: We have two goals for texture. One, we want to have a textural modifier where appropriate (i.e., CB, CBV, GR). Two, we want to have a texture (i.e., L, CL, SC). Ultimately, we want a single textural modifier and a single texture to represent the entire soil profile. We are starting off with textural modifiers and textures for each horizon, though. Therefore, we need to consider how to aggregate that data. Textural modifiers - For textural modifiers, we will choose the textural modifier from the thickest soil horizon and that textural modifier will be used as a value that represents the entire profile. Before doing that, we are going to change the depth of horizons that were not textured. For those horizons that were not textured, we are going to change the depth to 0.1 cm. This will prevent textural modifiers from being defined based on a horizon that was not textured. For example, a BR horizon is automatically assigned a depth of 25 cm. Depth of BR has limited ecological significance, and we do not want the texture of the soil profile to be determined by BR conditions. We are also specifically stating that texture is not equal to “BR” because several horizons that are BR have values of 0 for sand and clay when they should be NAs. horizon_df$thickness_modified &lt;- ifelse(is.na(horizon_df$clay), 0.1, ifelse(horizon_df$texture == &quot;BR&quot;, 0.1, horizon_df$thickness)) Now, we assign the textural modifier from the thickest horizon to the component. summarized_texture_qualifier &lt;- horizon_df %&gt;% dplyr::group_by(component, texture_qualifier) %&gt;% dplyr::summarize(combined_thickness = sum(thickness_modified)) %&gt;% dplyr::ungroup() %&gt;% dplyr::group_by(component) %&gt;% top_n(1, combined_thickness) %&gt;% ungroup() %&gt;% dplyr::select(-combined_thickness) Texture - Now, we are going to assign a texture to the entire profile. For texture, we have quantitative data (sand and clay percentages). This allows us to do a weighted average rather than just choosing the texture from the thickest horizon like we did for texture modifiers. First, we will remove horizons that do not have textures. We will also remove horizons labelled with texture as “BR” because some of those bedrock horizons have sand and clay percentages entered as zero rather than NA. Then, we group the horizons by the component id and calculate a weighted mean for clay/sand, pH, and rock frag using the horizon thickness as the weighting. weighted_texture &lt;- horizon_df %&gt;% dplyr::filter(!is.na(clay) &amp; !is.na(sand) &amp; texture != &quot;BR&quot;) %&gt;% dplyr::group_by(component) %&gt;% dplyr::summarise(clay_mean_texture = weighted.mean(clay, thickness_modified), sand_mean_texture = weighted.mean(sand, thickness_modified), ph_l_mean = weighted.mean(ph_l, thickness_modified), ph_r_mean = weighted.mean(ph_r, thickness_modified), ph_h_mean = weighted.mean(ph_h, thickness_modified), awc_l_sum = sum(awc_l * thickness_modified), awc_r_sum = sum(awc_r * thickness_modified), awc_h_sum = sum(awc_h * thickness_modified), rock_frag = weighted.mean(rock_frag, thickness_modified), depth_to_restr = sum(thickness_modified)) %&gt;% dplyr::mutate(textural_class = aqp::ssc_to_texcl(clay = clay_mean_texture, sand = sand_mean_texture)) Combine the texture qualifiers and the textures into a dataframe horizon_to_component_data &lt;- dplyr::left_join(summarized_texture_qualifier, weighted_texture) Component level data Here, we change gears and start assembling component level data. component_data &lt;- with(site(nasis_selection), data.frame( coiid = coiid, compname = compname, compkind = compkind, areasymbol = areasymbol, areaname = areaname, comppct_r = comppct_r, slope_l = slope_l, slope_r = slope_r, slope_h = slope_h, majcompflag = majcompflag, pmkind = pmkind, dmuiid = dmuiid, pmorigin = pmorigin, surf_frag = surface_total_frags_pct, elev_l = elev_l, elev_rv = elev_r, elev_h = elev_h, map_l = map_l, map_rv = map_r, map_h = map_h, maat_l = maat_l, maat_rv = maat_r, maat_h = maat_h, ffd_l = ffd_l, ffd_rv = ffd_r, ffd_h = ffd_h, aspectccwise = aspectccwise, aspectrep = aspectrep, aspectcwise = aspectcwise, landform = landform_string, taxtemp = taxtempregime, drainagecl = drainagecl, ecosite = ecosite_name, ecositeid = ecositeid, taxorder = taxorder, taxsuborder = taxsuborder ) ) Collect restriction data restriction_data &lt;- restrictions(nasis_selection) %&gt;% dplyr::select(coiid, reskind, resdept_l, resdept_r, resdept_h, reshard) %&gt;% subset(!grepl(&quot;noncemented&quot;, reshard)) %&gt;% dplyr::group_by(coiid) %&gt;% arrange(resdept_r) %&gt;% dplyr::slice(1) Merge component data and restriction data component_data_combined &lt;- left_join(component_data, restriction_data) ## Joining with `by = join_by(coiid)` Merge horizon data and component data all_data &lt;- horizon_to_component_data %&gt;% dplyr::rename(coiid = component) %&gt;% left_join(component_data_combined) %&gt;% dplyr::select(coiid, compname, ecosite, ecositeid, landform, pmkind, pmorigin, taxtemp, textural_class, texture_qualifier, rock_frag, surf_frag, depth_to_restr, drainagecl, slope_l, slope_r, slope_h, ph_l_mean, ph_r_mean, ph_h_mean, elev_l, elev_rv, elev_h, map_l, map_rv, map_h, maat_l, maat_rv, maat_h, ffd_l, ffd_rv, ffd_h ,comppct_r, dmuiid, everything()) Save as csv write.csv(all_data, &quot;C:/Users/Nathan.Roe/Downloads/my_ecosite_report.csv&quot;, row.names = FALSE) 3.7 Where do components occur? 3.8 How to correlate components to ecosites? 3.9 How to QC the correlation between 3.10 Test section "],["ecosites.html", "Chapter 4 Ecosites 4.1 What ecosites are active in an MLRA? 4.2 Range in characteristics of ecosites 4.3 Mapping ecological sites 4.4 Climate 4.5 Associated sites 4.6 Determine acreage of single ecological site 4.7 Determine acreage of multiple ecological sites 4.8 Accessing plot level vegetation data", " Chapter 4 Ecosites 4.1 What ecosites are active in an MLRA? Load the Standard Dataset and packages. Then, we simply need to call the ecosite IDs or ecosite names, depending on your preference. Remember, remove head() to see the full list. head(my.components.MLRA$ecosite_id) ## [1] &quot;F018XI207CA&quot; NA &quot;R018XI101CA&quot; &quot;R018XI101CA&quot; &quot;R018XI101CA&quot; ## [6] &quot;F018XI201CA&quot; head(my.components.MLRA$ecosite_name) ## [1] &quot;Deep Volcanic Plateaus and Hills&quot; NA ## [3] &quot;Shallow Latite Ridgetops&quot; &quot;Shallow Latite Ridgetops&quot; ## [5] &quot;Shallow Latite Ridgetops&quot; &quot;Moderately Deep Thermic Foothills&quot; There are likely NAs (missing values) in the above list. This is because the above considers components are are minor and miscellaneous. We do not correlate ecosites to components that are minor and miscellaneous. It will likely be more useful to remove minor and miscellaneous componets: my.components.MLRA.reduced &lt;- my.components.MLRA %&gt;% aqp::site() %&gt;% filter(compkind != &quot;miscellaneous area&quot; &amp; majcompflag == &quot;1&quot;) head(my.components.MLRA.reduced$ecosite_id) ## [1] &quot;R018XI101CA&quot; &quot;R018XI101CA&quot; &quot;F018XI201CA&quot; &quot;F018XI201CA&quot; &quot;R018XI102CA&quot; ## [6] &quot;R018XI102CA&quot; head(my.components.MLRA.reduced$ecosite_name) ## [1] &quot;Shallow Latite Ridgetops&quot; ## [2] &quot;Shallow Latite Ridgetops&quot; ## [3] &quot;Moderately Deep Thermic Foothills&quot; ## [4] &quot;Moderately Deep Thermic Foothills&quot; ## [5] &quot;Thermic Ultramafic Foothills Extremely High Magnesium Content (Ca:Mg Ratio Less Than 0.5)&quot; ## [6] &quot;Thermic Ultramafic Foothills Extremely High Magnesium Content (Ca:Mg Ratio Less Than 0.5)&quot; We might also be interested to see how often different ecosites are used: table(my.components.MLRA.reduced$ecosite_id) %&gt;% as.data.frame() %&gt;% dplyr::rename(Ecosite = Var1) %&gt;% arrange(desc(Freq)) %&gt;% head() ## Ecosite Freq ## 1 F022AI201CA 23 ## 2 F018XI201CA 22 ## 3 F018XI200CA 21 ## 4 F022AI202CA 19 ## 5 F018XI202CA 17 ## 6 F022AG202CA 14 Interesting… the most used ecosites in MLRA18 are ecosite concepts from MLRAs 22a and 17. 4.2 Range in characteristics of ecosites I created a report that summarizes the characteristics of ecosites. It is organized based on the information that is supposed to be populated in EDIT. Here is a link to a sample report. I have established a methodology allowing you to create reports like the one linked for all of the ecosites in your MLRA within a few short steps. You can also produce the report for just one of your ecosites. For documentation on this methodology, click here. Click on the green ‘Code’ button and choose ‘Download ZIP’. Once you have downloaded to the location of your preference, you can right click &gt; Extract all. You can then open the read_me.docx file. Additionally, you can watch the following YouTube video: 4.3 Mapping ecological sites For this methodology, the ecological site is mapped in all map units containing a component correlated to the ecological site. The alternative would be to map the ecological site only in map units where the dominant component is correlated to the ecological site of interest. I am more interest in the full extent of the ecological site, so I am using the less restrictive of the two. Load the Standard Dataset and packages. Load a shapefile of your map unit boundaries (the MLRA boundaries cover the whole country, but you will have to change the map unit boundaries to your local map unit shapefile) mapunit_boundaries &lt;- sf::read_sf(&quot;C:/Users/Nathan.Roe/Documents/PES/gSSURGO_CA_2022.gdb&quot;, &quot;mupolygon&quot;) mlra_boundaries &lt;- sf::read_sf(&quot;C:/Users/Nathan.Roe/Documents/PES/MLRA_52_2022/MLRA_52_2022/MLRA_52.shp&quot;) What is your ecological site of interest? (change appropriate to your project) ecosite_of_interest &lt;- &quot;R018XE104CA&quot; What is your MLRA of interest? (change appropriate to your project) mlra_of_interest &lt;- 18 Reduce component data to those associated with ecosite of interest my.components.MLRA.reduced &lt;- aqp::site(my.components.MLRA) %&gt;% filter(ecosite_id == ecosite_of_interest) Reduce mapunits to those associated with ecosite of interest mapunit_boundaries_of_interest &lt;- mapunit_boundaries %&gt;% dplyr::filter(MUKEY %in% my.components.MLRA.reduced$muiid) %&gt;% sf::st_transform(&quot;+proj=longlat +datum=WGS84&quot;) Reduce MLRA boundary to MLRA of interest mlra_boundaries_reduced &lt;- mlra_boundaries %&gt;% dplyr::filter(MLRARSYM == mlra_of_interest) %&gt;% sf::st_transform(&quot;+proj=longlat +datum=WGS84&quot;) Select state of interest (change appropriate to your project, you could select multiple states too) ca &lt;- st_as_sf(maps::map(&quot;state&quot;, fill = TRUE, plot = FALSE)) %&gt;% dplyr::filter(ID == &quot;california&quot;) %&gt;% sf::st_transform(&quot;+proj=longlat +datum=WGS84&quot;) Plot map ggplot() + theme_minimal() + geom_sf(data = ca) + geom_sf(data = mlra_boundaries_reduced) + geom_sf(data = mapunit_boundaries_of_interest, col = &quot;hotpink&quot;, alpha = 0, size = 2) + ggtitle(paste0(&quot;Distribution of ecological site - &quot;, ecosite_of_interest)) 4.4 Climate At a large scale, climate is the most important abiotic variable affecting the distribution of organisms. In ecological site concept development, it is a critical starting place. This section will introduce functions that can help report the climate associated with an ecoligcal site by summarizing PRISM climate data (https://prism.oregonstate.edu/). PRISM data is 800m raster data that includes precipitation, temperature, vapor pressure, and dew point. The primary product of PRISM is climate normals. PRISM normals are averages of climate conditions across a 30-year time frame. There are annual normals, monthly normals, and daily normals. There are 365 daily normals (one for each day), 12 monthly normals (one for each month), and only one annual normal. As an example of how normals work, consider precipitation on the 12th day of the year across the time period 1991-2020. There are 30 years of data, each with a 12th day and an associated estimate of precipitation. Those 30 estimates are averaged. The result is the daily normal for the 12th day of the year. The same process can be applied for the other days of the year. 4.5 Associated sites Associated sites are ecological sites that occur in the same area of the landscape. The simplest way to think about this is ecological sites that are adjacent to your ecological site of interest. I am going to present a simple way of addressing this. We can determine what ecological sites occur in the same mapunit as your ecosite of interest. Looking at all the mapunits that your ecological site of interest occurs in, and tallying up all of the other ecological sites that are in shared mapunits, we can come to a metric of what other ecological sites tend to be near your ecological site of interest. In the future, I would like to make some improvements to this, so that it considers adjacent mapunits and considers the length of boundary between mapunits. Load the Standard Dataset and packages. Reduce data how you see fit. I am just going to remove miscellaneous areas, but you could choose additional criteria such as removing minor components. my.components.MLRA.reduced &lt;- my.components.MLRA@site |&gt; dplyr::filter(compkind != &quot;miscellaneous area&quot;) Calculate the acreage associated with each component my.components.MLRA.reduced$comp_acres &lt;- (my.components.MLRA.reduced$muacres * my.components.MLRA.reduced$comppct_r)/100 Create empty list for upcoming for loop associated_ecosites &lt;- list() Create for loop to calculate the acreage of ecosites that occur in the same mapunits as your ecosite of interest. The results will be in a list. for(i in my.components.MLRA.reduced$ecosite_id |&gt; unique()){ associated_ecosites[[i]] &lt;- my.components.MLRA.reduced |&gt; dplyr::filter(mukey %in% (my.components.MLRA.reduced |&gt; dplyr::filter(ecosite_id == i) |&gt; dplyr::pull(mukey))) |&gt; dplyr::group_by(ecosite_id) |&gt; dplyr::summarise(acres = sum(comp_acres)) |&gt; dplyr::filter(ecosite_id != i) |&gt; arrange(dplyr::desc(acres)) } Let’s take a look at an example associated_ecosites$F018XA202CA ## NULL 4.6 Determine acreage of single ecological site My office leader recently asked me how many acres a particular ecological site occupies because she was entering it as a project in NASIS and needed the associated acres. You might need to do something similar for a NASIS project, a tech team meeting, or to improve your own understanding of how prevalent an ecological site is. Load the Standard Dataset and packages. First, let’s say we have a particular ecosite of interest - “R018XI105CA” my_ecosite &lt;- aqp::site(my.components.MLRA) %&gt;% dplyr::filter(ecosite_id == &quot;R018XI105CA&quot;) Now let’s look at the components correlated to our ecosite of interest, the component percent (percent of mapunit represented by component), the mapunit acres, and calculate the acres associated with each component by multiplying component percent and mapunit acres. my_ecosite_compacres &lt;- my_ecosite %&gt;% select(ecosite_id, coiid, comppct_r, muacres) %&gt;% mutate(comp_acreage = (comppct_r/100)*muacres) head(my_ecosite_compacres) ## ecosite_id coiid comppct_r muacres comp_acreage ## 1 R018XI105CA 2516892 25 5717 1429.25 ## 2 R018XI105CA 2029027 10 34449 3444.90 ## 3 R018XI105CA 2500528 17 34449 5856.33 ## 4 R018XI105CA 1842728 25 7447 1861.75 ## 5 R018XI105CA 2029025 10 7447 744.70 ## 6 R018XI105CA 2482828 15 22906 3435.90 Then, we just need to sum the comp_acreage sum(my_ecosite_compacres$comp_acreage) ## [1] 30098.78 4.7 Determine acreage of multiple ecological sites Let’s look at how we would efficiently calculate the acreage of all the ecosites in your MLRA. First, we will restrict the ecosites of interest to only those associate with MLRA 18. MLRA18_ecosites &lt;- my.components.MLRA$ecosite_id %&gt;% str_subset(pattern = &quot;18X&quot;) %&gt;% unique() Now we can run a for loop that goes through each ecological site, calculates the acreage, and puts them all in a data frame ecosite_list &lt;- list() for(i in MLRA18_ecosites){ ecosite_list[[i]] &lt;- aqp::site(my.components.MLRA) %&gt;% dplyr::filter(ecosite_id == i) %&gt;% select(ecosite_id, coiid, comppct_r, muacres) %&gt;% mutate(comp_acreage = (comppct_r/100)*muacres) %&gt;% summarise(Ecosite = first(ecosite_id), Acreage = sum(comp_acreage)) } MLRA18_ecosite_acreage &lt;- do.call(rbind, ecosite_list) %&gt;% remove_rownames() head(MLRA18_ecosite_acreage) ## Ecosite Acreage ## 1 F018XI207CA 19275.91 ## 2 R018XI101CA 4999.80 ## 3 F018XI201CA 154095.87 ## 4 F018XI200CA 111078.29 ## 5 F018XI202CA 69860.72 ## 6 R018XI102CA 18123.88 4.8 Accessing plot level vegetation data For this process, we are going to look at vegetation data associated with the Sequoia and King’s Canyon National Parks soil survey - CA792. For accessing vegetation data associated with a survey area, use the following query - SSRO_Alaska &gt; ‘Pedon/Site/Vegetation Plot by site area overlap table’. The description for this Query gives the necessary details. NATIONAL: Have to run this twice against the national in order to get sites, pedons, and vegetation plot. First, set target table to PEDON. Second, set target tablet to VEGETATION PLOT. LOCAL: Set target tablest to PEDON, SITE, and VEGETATION PLOT. Run against National - Pedon Run against National - Vegetation plot Run against Local veg_data &lt;- soilDB::fetchVegdata(SS = TRUE) I will return to this to provide some tools for dealing with the actual veg data. test &lt;- data.frame(UserSiteID = veg_data$vegplot$site_id, DataOrigin = veg_data$vegplot$vegdataorigin) table(test$DataOrigin) ## ## site existing veg table spreadsheet form ## 620 1006 "],["species.html", "Chapter 5 Species 5.1 Creating a species list 5.2 Working with vegetation data 5.3 Mapping the location of species", " Chapter 5 Species 5.1 Creating a species list Here is a brief introduction to create a species list from your selected set in NASIS. This can be helpful to provide to folks who are less familiar with the vegetation of an area, so that they know what species have been observed. The function accesses the USDA PLANTS database and returns modern taxonomies if old taxa exist in the dataset, functional class, plant family, and native status. species_list &lt;- ecositer::species_list(SS = TRUE) ## Current.Symbol Current.Sci.Name Accepted.Symbol ## 1 LOIN4 Lonicera interrupta LOIN4 ## 2 TODI Toxicodendron diversilobum TODI ## 3 CASO2 Calystegia soldanella CASO2 ## 4 GATR2 Galium trifidum GATR2 ## 5 GATR3 Galium triflorum GATR3 ## 6 CLLA3 Clematis lasiantha CLLA3 ## Accepted.Sci.Name Common.Name Growth.Habit ## 1 Lonicera interrupta chaparral honeysuckle Vine, Shrub ## 2 Toxicodendron diversilobum Pacific poison oak Vine, Shrub ## 3 Calystegia soldanella seashore false bindweed Vine, Forb/herb ## 4 Galium trifidum threepetal bedstraw Vine, Forb/herb ## 5 Galium triflorum fragrant bedstraw Vine, Forb/herb ## 6 Clematis lasiantha pipestem clematis Vine ## Native.Status Family Order ## 1 L48(N) Caprifoliaceae Dipsacales ## 2 L48(N)CAN(N) Anacardiaceae Sapindales ## 3 L48(N)CAN(N) Convolvulaceae Solanales ## 4 L48(N)AK(N)CAN(N)GL(N)SPM(N) Rubiaceae Rubiales ## 5 L48(N)AK(N)CAN(N)GL(I?)SPM(N) Rubiaceae Rubiales ## 6 L48(N) Ranunculaceae Ranunculales 5.2 Working with vegetation data To begin with, we will query plot level NASIS data using the query outlined in Accessing plot level vegetation data. Then, run ecositer::vegStaticNASIS() and ecositer::formatted_veg_df(). See the Vegetation data QC is a critical step in ecological data analysis. The USDA plants database improves vegetation data quality, ensuring proper scientific names are used, but additional QC must be performed. One of the primary tasks will be dealing with identifications to different taxonomic levels (i.e., genus, species, and subspecies). Statistical approaches think of each class separately and therefore do not recognize any similarity between taxonomic levels. For example, statistical analyses do not recognize any relationship between Pinus, Pinus contorta, and Pinus contorta var. murrayana. For this reason, you will need to determine how to modify your data based on the characteristics of your data set and expert knowledge. This will likely need to be done on a species-by-species basis. The ultimate goal is to group all of the observations of one organism into one class. Below is an example of this process and code you can use to assist: To begin with, I will look at all of the plant names used: 5.3 Mapping the location of species Let’s take a look at the location of species. To do this we will query plot level NASIS data using the query outlined in Accessing plot level vegetation data. Once you have queried, you can filter your dataset for any species of interest. I am going to search for a genus - Artemisia (sagebrush). Ultimately, we will produce a map that shows the distribution of all the species of Artemisia. veg_data &lt;- fetchVegdata(dsn = &quot;C:/Users/Nathan.Roe/Documents/SEKI/CA792_veg_data.sqlite&quot;, SS = FALSE) ## NOTE: some siteobsiid have surface fragment cover &gt;= 100% artemesia_df &lt;- veg_data$vegplotspecies %&gt;% filter(plantsciname %in% str_subset(veg_data$vegplotspecies$plantsciname, &quot;Artemisia&quot;)) %&gt;% select(siteiid, plantsciname) Query for Artemisia and create a spatial dataframe with coordinates artemesia_df &lt;- veg_data$vegplotspecies %&gt;% filter(plantsciname %in% str_subset(veg_data$vegplotspecies$plantsciname, &quot;Artemisia&quot;)) %&gt;% select(siteiid, plantsciname) artemesia_location &lt;- veg_data$vegplotlocation %&gt;% dplyr::filter(siteiid %in% artemesia_df$siteiid) %&gt;% select(siteiid, utmzone, utmeasting, utmnorthing) %&gt;% dplyr::left_join(artemesia_df) %&gt;% st_as_sf(coords = c(&#39;utmeasting&#39;, &#39;utmnorthing&#39;), crs = st_crs(32611)) ## Joining with `by = join_by(siteiid)` ## Warning in dplyr::left_join(., artemesia_df): Detected an unexpected many-to-many ## relationship between `x` and `y`. ## ℹ Row 1 of `x` matches multiple rows in `y`. ## ℹ Row 7 of `y` matches multiple rows in `x`. ## ℹ If a many-to-many relationship is expected, ## set `relationship = &quot;many-to-many&quot;` to ## silence this warning. Create a list of dataframes based on the different veg_data &lt;- fetchVegdata(dsn = &quot;C:/Users/Nathan.Roe/Documents/SEKI/CA792_veg_data.sqlite&quot;, SS = FALSE) ## NOTE: some siteobsiid have surface fragment cover &gt;= 100% artemesia_df &lt;- veg_data$vegplotspecies %&gt;% filter(plantsciname %in% str_subset(veg_data$vegplotspecies$plantsciname, &quot;Artemisia&quot;)) %&gt;% select(siteiid, plantsciname) artemesia_location &lt;- veg_data$vegplotlocation %&gt;% dplyr::filter(siteiid %in% artemesia_df$siteiid) %&gt;% select(siteiid, utmzone, utmeasting, utmnorthing) %&gt;% dplyr::left_join(artemesia_df) %&gt;% st_as_sf(coords = c(&#39;utmeasting&#39;, &#39;utmnorthing&#39;), crs = st_crs(32611)) ## Joining with `by = join_by(siteiid)` ## Warning in dplyr::left_join(., artemesia_df): Detected an unexpected many-to-many ## relationship between `x` and `y`. ## ℹ Row 1 of `x` matches multiple rows in `y`. ## ℹ Row 7 of `y` matches multiple rows in `x`. ## ℹ If a many-to-many relationship is expected, ## set `relationship = &quot;many-to-many&quot;` to ## silence this warning. artemesia_location_split &lt;- split(artemesia_location, artemesia_location$plantsciname) my_colors &lt;- RColorBrewer::brewer.pal(n = length(artemesia_location_split), name = &#39;Set1&#39;) mapview::mapView(artemesia_location_split, col.regions = my_colors) It can be really useful to create a stored version of your selected set. That way, if you are frequently changing between different different selected sets, you do not have to clear your selected set and run a new query. This can be done by saving your selected set as an SQlite database. This allows you to call the saved SQlite database in SoilDB functions. Let’s look at how we can create a stored SQlite database. soilDB::createStaticNASIS(SS = TRUE, tables = soilDB::get_NASIS_table_name_by_purpose(c(&quot;area&quot;, &quot;legend&quot;, &quot;mapunit&quot;, &quot;datamapunit&quot;, &quot;component&quot;, &quot;metadata&quot;, &quot;lookup&quot;, &quot;nasis&quot;)), output_path = &quot;C:/Users/Nathan.Roe/Documents/SEKI/CA792_veg_data.sqlite&quot;) Note: The tables listed in the get_NASIS_table_name_by_purpose argument should cover the majority of situations. If you run into an issue, though, soilDB will likely name a specific table that is missing. If that happens, you will have to add the table to the character vector. Once you have stored your SQlite database, you can call it using the soilDB functions. The default argument in fetchNASIS() and other SoilDB functions is SS = TRUE. We are going to change that to false and identify the location of the SQlite database in the dsn argument. my.components.MLRA &lt;- fetchNASIS(from = &quot;components&quot;, duplicates = T, dsn = &quot;C:/Users/Nathan.Roe/Documents/SEKI/CA792_veg_data.sqlite&quot;, SS = FALSE) This can be extremely useful when you have multiple selected sets that you are working with. "],["nasis.html", "Chapter 6 NASIS 6.1 Creating a Static NASIS database", " Chapter 6 NASIS 6.1 Creating a Static NASIS database It can be really useful to create a stored version of your selected set. That way, if you are frequently changing between different different selected sets, you do not have to clear your selected set and run a new query. This can be done by saving your selected set as an SQlite database. This allows you to call the saved SQlite database in SoilDB functions. Let’s look at how we can create a stored SQlite database. soilDB::createStaticNASIS(SS = TRUE, tables = soilDB::get_NASIS_table_name_by_purpose(c(&quot;area&quot;, &quot;legend&quot;, &quot;mapunit&quot;, &quot;datamapunit&quot;, &quot;component&quot;, &quot;metadata&quot;, &quot;lookup&quot;, &quot;nasis&quot;)), output_path = &quot;C:/Users/Nathan.Roe/Documents/SEKI/vegplotdata.sqlite&quot;) Note: The tables listed in the get_NASIS_table_name_by_purpose argument should cover the majority of situations. If you run into an issue, though, soilDB will likely name a specific table that is missing. If that happens, you will have to add the table to the character vector. Once you have stored your SQlite database, you can call it using the soilDB functions. The default argument in fetchNASIS() and other SoilDB functions is SS = TRUE. We are going to change that to false and identify the location of the SQlite database in the dsn argument. my.components.MLRA &lt;- fetchNASIS(from = &quot;components&quot;, duplicates = T, dsn = &quot;C:/Users/Nathan.Roe/Documents/SEKI/vegplotdata.sqlite&quot;, SS = FALSE) This can be extremely useful when you have multiple selected sets that you are working with. "],["es-verification.html", "Chapter 7 ES Verification 7.1 Prioritization", " Chapter 7 ES Verification 7.1 Prioritization 7.1.1 Guidance from National Instruction This section is intended to assist with ES Verification projects. The National Instruction with full details of verification project requirements can be accessed here - Part 306 – Ecological Site Inventory and Ecological Site Description. This workflow addresses many of the requirements outlined section 306.6.C.2 from the National Instruction, shown in the photo below: 306.6.C.2 from National Instruction 7.1.2 Goal of with workflow The goal of this methodology is to determine what data is available to use for ES Verification Projects. It reports on data elements listed in the ES Verification standards as well as other elements that are not required but are indicative of data quality, including: correlated pedons &amp; vegplots (including whether they are colocated) use of states and phases canopy cover by species (plant symbol &amp; cover) strata number components correlated to ecosite number of acres component pedons taxonomic level (i.e., series, family, taxadjunct, etc.) There are two main outputs. For both of the visuals below there are more columns than are able to be shown: The first shows the amount of supporting data for the ecosites in your MLRA. The second allows users to look at specific ecosites and determine what sites have the best data and could be used as supporting evidence of the ES. 7.1.3 YouTube summary 7.1.4 Querying NASIS This process requires two different NASIS queries. First to access site/pedon/vegplot data, and the other to access component data associated with your MLRA. Before getting started, clear selected set. Query 1 (site/pedon/vegetation plot) Run “SSRO_Southwest &gt; Sites by ecositeid with %” (not listed as ready for use) using an appropriate pattern for Ecological Site ID (e.g., %018X% for MLRA18) Query 2 (components) Use https://nroe.shinyapps.io/MapunitsInMLRA/ to access all mukeys in your MLRA of interest. Mukeys are batched into groups of 2100 parameters on each tab, as this is the limit that NASIS accepts as arguments in a query. Read the instructions on the page for details. If multiple tabs are populated, the query will have to be run multiple times. Use these mukeys as input into “NSSC Pangaea &gt; Area/Legend/Mapunit/DMU by record ID - LMAPUNITIID”. 7.1.5 Run workflow Access data from NASIS # library library(soilDB) library(dplyr) # access veg data MLRA18_veg &lt;- ecositer::create_veg_df(from = &quot;SS&quot;) # access pedon data MLRA18_pedons &lt;- fetchNASIS(from = &quot;pedons&quot;) # access component data MLRA18_components &lt;- fetchNASIS(from = &quot;components&quot;, fill = TRUE, duplicates = TRUE) # access component pedon data - you will be notified that, &quot;some linked pedons not in selected set or local database&quot; MLRA18_component_pedons &lt;- soilDB::get_copedon_from_NASIS_db() Summarize data # Manipulating data ------------------------------------------------------ # aggregate abundance columns MLRA18_veg_agg &lt;- ecositer::QC_aggregate_abundance(veg_df = MLRA18_veg) # select component columns of interest and calculate comp_acres MLRA18_components_mod &lt;- MLRA18_components |&gt; aqp::site() |&gt; dplyr::select(mukey, coiid, compname, majcompflag, compkind, ecosite_id, muacres, comppct_r) |&gt; dplyr::mutate(comp_acres = muacres * comppct_r/100, ecositeid = ecosite_id) # Joining data ----------------------------------------------------------- # join component pedons to pedons MLRA18_pedons_coped &lt;- aqp::site(MLRA18_pedons) |&gt; dplyr::left_join(MLRA18_component_pedons |&gt; dplyr::mutate(peiid = as.character(peiid)) |&gt; dplyr::select(-upedonid)) # join pedon data to veg data MLRA18_veg_peiid &lt;- MLRA18_veg_agg |&gt; dplyr::left_join(MLRA18_pedons_coped |&gt; dplyr::select(siteobsiid, peiid, coiid, pedon_id, representative, rvindicator) |&gt; dplyr::mutate(siteobsiid = as.character(siteobsiid)) |&gt; unique() |&gt; dplyr::group_by(siteobsiid) |&gt; dplyr::arrange(pedon_id) |&gt; dplyr::slice(1)) # Summarizing data ------------------------------------------------------- MLRA18_triage &lt;- MLRA18_veg_peiid |&gt; dplyr::group_by(ecositeid, siteiid, siteobsiid, vegplotiid, peiid, pedon_id, representative, ecostateid, commphaseid) |&gt; dplyr::summarise(overcanclass = any(!is.na(overstorycancovtotalclass)), totcanclass = any(!is.na(cancovtotalclass)), heighclasslow = any(!is.na(plantheightcllowerlimit)), heighclasshigh = any(!is.na(plantheightclupperlimit)), planttypegroup = any(!is.na(planttypegroup)), akstratumclass = any(!is.na(akstratumcoverclass)), vegstrata = any(!is.na(vegetationstratalevel)), plantsym = any(!is.na(plantsym)), speciescancov = any(!is.na(pct_cover))) MLRA18_triage_summary &lt;- MLRA18_triage |&gt; dplyr::mutate(plant_abund = plantsym + speciescancov, heightlimit = heighclasslow + heighclasshigh) |&gt; dplyr::mutate(plant_abund_logic = ifelse(plant_abund == 2, TRUE, FALSE), heightlimit_logic = ifelse(heightlimit == 2, TRUE, FALSE)) |&gt; dplyr::mutate(strata = heightlimit_logic + planttypegroup + akstratumclass + vegstrata) |&gt; dplyr::mutate(strata_logic = ifelse(strata &gt;= 1, TRUE, FALSE)) |&gt; dplyr::mutate(sum_logic = sum(c(plant_abund_logic, strata_logic, overcanclass, totcanclass))) |&gt; dplyr::mutate(sum_logic_no_can = sum(c(plant_abund_logic, strata_logic))) MLRA18_ecosite_triage_summary &lt;- MLRA18_triage_summary |&gt; dplyr::group_by(ecositeid) |&gt; dplyr::summarise(pedons = sum(!is.na(peiid)), ecostateid = sum(!is.na(ecostateid)), commphaseid = sum(!is.na(commphaseid)), plant_abund = sum(!is.na(plant_abund_logic)), strata = sum(!is.na(strata_logic))) |&gt; dplyr::left_join(MLRA18_components_mod) |&gt; dplyr::group_by(ecositeid, pedons, ecostateid, commphaseid, plant_abund, strata) |&gt; dplyr::summarise(components = sum(!is.na(coiid)), acres = sum(comp_acres, na.rm = TRUE), majcomp = sum(majcompflag, na.rm = TRUE), series = sum(compkind == &quot;series&quot;, na.rm = TRUE), taxadjunct = sum(compkind == &quot;taxadjunct&quot;, na.rm = TRUE), family = sum(compkind == &quot;family&quot;, na.rm = TRUE), tax_above_fam = sum(compkind == &quot;taxon above family&quot;, na.rm = TRUE), variant = sum(compkind == &quot;variant&quot;, na.rm = TRUE), misc = sum(compkind == &quot;miscellaneous area&quot;, na.rm = TRUE)) head(MLRA18_ecosite_triage_summary) ## # A tibble: 6 × 15 ## # Groups: ecositeid, pedons, ecostateid, ## # commphaseid, plant_abund [6] ## ecositeid pedons ecostateid commphaseid plant_abund strata components acres ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 F001XA001WA 0 0 0 1 1 0 0 ## 2 F018XA201CA 0 0 0 54 54 66 3.29e4 ## 3 F018XA202CA 0 0 0 76 76 26 7.00e4 ## 4 F018XC110CA 1 1 1 1 1 0 0 ## 5 F018XC201CA 22 13 11 383 383 210 4.71e5 ## 6 F018XC203CA 20 9 8 48 48 20 2.29e4 ## # ℹ 7 more variables: majcomp &lt;int&gt;, series &lt;int&gt;, taxadjunct &lt;int&gt;, ## # family &lt;int&gt;, tax_above_fam &lt;int&gt;, variant &lt;int&gt;, misc &lt;int&gt; head(MLRA18_triage_summary) ## # A tibble: 6 × 26 ## # Groups: ecositeid, siteiid, siteobsiid, ## # vegplotiid, peiid, pedon_id, ## # representative, ecostateid [6] ## ecositeid siteiid siteobsiid vegplotiid peiid pedon_id representative ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 F001XA001WA 1868185 2338844 1173348 &lt;NA&gt; &lt;NA&gt; NA ## 2 F018XA201CA 1867763 2338220 1174740 &lt;NA&gt; &lt;NA&gt; NA ## 3 F018XA201CA 1867773 2338230 1174750 &lt;NA&gt; &lt;NA&gt; NA ## 4 F018XA201CA 1867775 2338232 1174752 &lt;NA&gt; &lt;NA&gt; NA ## 5 F018XA201CA 1867777 2338234 1174754 &lt;NA&gt; &lt;NA&gt; NA ## 6 F018XA201CA 1881378 2338235 1174755 &lt;NA&gt; &lt;NA&gt; NA ## # ℹ 19 more variables: ecostateid &lt;chr&gt;, commphaseid &lt;chr&gt;, overcanclass &lt;lgl&gt;, ## # totcanclass &lt;lgl&gt;, heighclasslow &lt;lgl&gt;, heighclasshigh &lt;lgl&gt;, ## # planttypegroup &lt;lgl&gt;, akstratumclass &lt;lgl&gt;, vegstrata &lt;lgl&gt;, ## # plantsym &lt;lgl&gt;, speciescancov &lt;lgl&gt;, plant_abund &lt;int&gt;, heightlimit &lt;int&gt;, ## # plant_abund_logic &lt;lgl&gt;, heightlimit_logic &lt;lgl&gt;, strata &lt;int&gt;, ## # strata_logic &lt;lgl&gt;, sum_logic &lt;int&gt;, sum_logic_no_can &lt;int&gt; "],["package-buildingmaintaining-tips.html", "Chapter 8 Package building/maintaining tips 8.1 Package building/maintaining tips", " Chapter 8 Package building/maintaining tips 8.1 Package building/maintaining tips This section has helpful reminders for building and maintaining R packages. Update package documentation # devtools::document() Add package # use_package() Add function from package. Adding a function from a package instead of the whole package keeps things lighter weight. If you want to just add a function, use the script below and put it in your function.R file where you use their function. # @importFrom package-name object1 object2 objectn Make a package documentation file # usethis::use_package_doc() Check out this link for more details - https://devtools.r-lib.org/ "],["random-tools.html", "Chapter 9 Random tools 9.1 Organizing scanned data 9.2 Comparing Bray-Curtis and Jaccard (dis)similarity measures", " Chapter 9 Random tools 9.1 Organizing scanned data Digitizing and organizing datasheets can be tedious. The following workflow automates this process, removing the need to create/name folders, name files, scan documents individually (or manually separate), and sort files into the appropriate folder. Instead, you can bulk scan (feed your whole stack to the scanner at once) and create a single pdf file. Then, using R we will separate that file into individual pdfs, one pdf for each site. Each pdf will be named using the site id and put in a folder using the same site id. Let’s go over the steps - Organize your paper datasheets in numerical order Scan your paper datasheets using the office scanner. You should be able to feed all of the datasheets in at once. The result is a single pdf file with all of your sites. Determine the site numbers. This step requires either extracting the site numbers from a GPS device, NASIS, or some other source OR typing the site numbers manually. Typing the site numbers manually would look like this: my_site_number &lt;- c(401, 402, 403, 404, 405) Depending on what you have available and your skillset (willing to use soilDB to pull sites/pedons under your name in NASIS, etc.), you may have to enter this manually. Fortunately, this will be the only manual part of the workflow. Install the ecositer R package remotes::install_github(&quot;natearoe/ecositer&quot;, dependencies = FALSE) Look at the help file for the scanned_data_organizer() function in R ?ecositer::scanned_data_organizer() Run scanned data_organizer(). Remember that your paths need to have forward slashes, not back slashes. That’ll be a show stopper. I do find and replace all. Also, make sure you have created a vector of site numbers, that needs to be called in the site_number argument. Here is an example of running scanned_data_organizer(): ecositer::scanned_data_organizer(scanned_data_path = &quot;S:/NRCS/XEROX SCANS/DOC057.pdf&quot;, directory = &quot;C:/Users/Nathan.Roe/Documents/Alaska2023/Willow_project&quot;, year_state_fips = &quot;2023AK185&quot;, site_number = my_site_number) That’s it! You now have a folder for each site that contains a pdf of that site’s datasheet. There is also an all_sites folder containing all of the site pdfs together in one location. 9.2 Comparing Bray-Curtis and Jaccard (dis)similarity measures Bray-Curtis (similarity): \\(\\frac{2 * A \\cap B}{\\left(A \\cap B\\right) + \\left(A \\cup B\\right)}\\) Bray-Curtis (dissimilarity): \\(1 - \\frac{2 * A \\cap B}{\\left(A \\cap B\\right) + \\left(A \\cup B\\right)}\\) Jaccard (similarity): \\(\\frac{A \\cap B}{A \\cup B}\\) Jaccard (dissimilarity): \\(1 - \\frac{A \\cap B}{A \\cup B}\\) Both Bray-Curtis and Jaccard are proportional coefficients that express the proportion of the maximum distance possible. The numerators of Bray-Curtis and Jaccard, measures of shared abundance, are relativized by total abundance or unshared abundance, respectively. The numerators are essential the same, both being directly related to \\(A \\cap B\\) (hereon referred to as shared abundance). Given that shared abundance drives both measures, I propose examining the response of both measures along a gradient of shared abundance. The gradient of shared abundance will vary from 0 to 1. The total abundance will remain fixed at 1. Simulate shared abundance and calculate both measures # create a gradient of proportion shared abundance prop_sim &lt;- matrix(data = seq(0, 1, 0.01)) # calculate bray bray &lt;- apply(prop_sim, MARGIN = 2, FUN = function(x){ x/1 # &quot;1&quot; could also be max(x) }) # calculate jaccard jaccard &lt;- apply(prop_sim, MARGIN = 2, FUN = function(x){ 0.5*x/(1 - 0.5*x) # &quot;1&quot; could also be max(x) }) # put results in dataframe my_results &lt;- data.frame(prop_sim = prop_sim, bray = bray, jaccard = jaccard) # calculate difference between bray and jaccard my_results$diff &lt;- abs(my_results$bray - my_results$jaccard) # calculate dissimilarities my_results$bray_dis &lt;- 1 - my_results$bray my_results$jaccard_dis &lt;- 1 - my_results$jaccard Plot the relationship between Bray-Curtis and Jaccard my_results_long &lt;- tidyr::pivot_longer(my_results, cols = c(&quot;bray&quot;, &quot;jaccard&quot;, &quot;bray_dis&quot;, &quot;jaccard_dis&quot;)) my_results_long$type &lt;- ifelse(grepl(&quot;dis&quot;, my_results_long$name) == TRUE, &quot;Dissimilarity&quot;, &quot;Similarity&quot;) my_colors &lt;- c(&quot;#999999&quot;) ggplot2::ggplot(data = my_results_long, ggplot2::aes(x = prop_sim, y = value, color = name)) + ggplot2::geom_path(size = 1) + ggplot2::xlab(&quot;Shared abundance&quot;) + ggplot2::ylab(&quot;Value&quot;) + ggplot2::labs(color = &quot;Measure&quot;) + ggplot2::scale_color_manual(labels = c(&quot;Bray-Curtis (sim)&quot;, &quot;Bray-Curtis (dis)&quot;, &quot;Jaccard (sim)&quot;, &quot;Jaccard (dis)&quot;), values = c(&quot;#F8766D&quot;, &quot;#7CAE00&quot;, &quot;#00BFC4&quot;, &quot;#C77CFF&quot;)) Bray-Curtis is linear with a slope of 1 or -1. Jaccard is non-linear. To determine how the slope of Jaccard changes over a gradient of shared abundance, I will differentiate Jaccard (sim). my_results$jaccard_deriv &lt;- apply(prop_sim, MARGIN = 2, FUN = function(x){ 0.5/(1-.5*x)^2 }) ggplot2::ggplot(data = my_results, ggplot2::aes(x = prop_sim, y = jaccard_deriv)) + ggplot2::geom_path(size = 1) + ggplot2::xlab(&quot;Shared abundance&quot;) + ggplot2::ylab(&quot;1st derivative of Jaccard similarity&quot;) The derivative of Jaccard (sim) shows us that changes to shared abundance at low levels of shared abundance have 1/4 of the influence as changes to shared abundance at high levels of shared abundance. This is observable from the 1st derivative being 0.5 at low levels of shared abundance and 2 at high levels of shared abundance. This could be a useful property if low amounts of shared abundance could be considered spurious. Finally, let’s look at disagreement between Jaccard and Bray-Curtis. ggplot2::ggplot(data = my_results, ggplot2::aes(x = prop_sim, y = diff)) + ggplot2::geom_path(size = 1) + ggplot2::xlab(&quot;Shared abundance&quot;) + ggplot2::ylab(&quot;Abs. value diff. of Bray-Curtis and Jaccard&quot;) my_results |&gt; dplyr::select(prop_sim, diff) |&gt; dplyr::arrange(desc(diff)) |&gt; head() ## prop_sim diff ## 1 0.59 0.1715603 ## 2 0.58 0.1715493 ## 3 0.60 0.1714286 ## 4 0.57 0.1713986 ## 5 0.61 0.1711511 ## 6 0.56 0.1711111 The greatest disagreement occurs at a shared abundance of 0.59. Above a shared abundance of 0.59, Jaccard accelerates, converging with Bray-Curtis at a share abundance of 1 in a shared abundance distance of 0.41. Below a shared abundance of 0.59, Jaccard takes longer to converge with Bray-Curtis, converging at 0 in a shared abundance distance of 0.59. This trend is consistent with the accelerating slope of Jaccard. In summary, Bray-Curtis treats changes to shared abundance as a linear function. Any change in shared abundance has equal importance across a gradient of shared abundance. In fact, the shared abundance value used in this comparison is in essence Bray-Curtis itself. Alternatively, Jaccard considers changes to shared abundance at low levels of shared abundance to be less important than changes at high levels of shared abundance. Basically, low levels of shared abundance are considered more spurious than high levels. There are several reasons why this may be true, including accounting for shared abundance between ubiquitous, cosmopolitan species in otherwise dissimilar plots or having shared abundance in dissimilar plots due to a misidentified species. ``` "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
