[["index.html", "NRCS Ecologist FAQs Chapter 1 Introduction 1.1 Overview 1.2 OBCD Connection", " NRCS Ecologist FAQs Nathan Roe - nateroe@gmail.com 2022-05-24 Chapter 1 Introduction This documents outlines common methodologies used by NRCS Ecologists. It is intended to be an educational resource and to develop best practice standards. This is intended to be a living document. If you have recommendations for best practices or additional practices that should be added, please let me know! 1.1 Overview This document is divided into 4 sections: mapunits, components, plots, and ecosites. Within those sections are commonly used methodologies relating to the section concept. For example, within the components section are methodologies relating to the use of components (i.e., What are the ecological characteristics of components?). Much of this methodology relies on a combination of NASIS and R. It is my objective to make the R examples clear enough that someone with minimal to no experience with R can reproduce these examples. 1.2 OBCD Connection As mentioned, these methodologies frequently utilize R and NASIS. To accomplish this, you will need to have R installed and establish an ODBC connection to NASIS. This is outlined in detail by the NRCS Stats for Soil Survey pre-course assignment. "],["mapunits.html", "Chapter 2 Mapunits 2.1 What mapunits are in an MLRA? 2.2 What mapunits are in a Soil Survey Area? 2.3 Mapping mapunits", " Chapter 2 Mapunits This section deals with mapunits. Mapunits have limited application for ecological work because they are broad concepts. Mapunits frequently contain multiple components, each occurring on different parts of the landscape and having different soil properties. Ecosites are correlated to components rather than mapunits because of the variability of mapunits. It should be noted that mapunits are spatially delineated, though, whereas components are not. Therefore, an attempt to map ecosites would rely heavily on mapunit delineations. An example of this can be seen on Web Soil Survey. Web Soil Survey can be used to map ecosites. These maps use mapunit delineations and show the ecosites that are correlated to the dominant component in that mapunit. For the purpose of this document, mapunits are primarily used as intermediate steps in different methodologies. For example, some NASIS Reports are particularly useful and require mapunits as input. Therefore, determining what mapunits are in your area of interest is helpful. The NRCS has four soil mapping products: SSURGO, gSSURGO, STATSGO, and gNATSGO. SSURGO is the most detailed product but is not available in all areas of the country. The resolution of SSURGO data ranges from 1:12,0000 to 1:63,360. gSSURGO is a gridded (rasterized) version of SSURGO - hence the g prefix. It covers the same areas as SSURGO but is gridded at a 10-meter cell size. STATSGO is a less detailed product but is available across all parts of the US. The resolution is 1:250,0000 in the continental US, Hawaii, Puerto Rico and the Virgin Islands. In Alaska, the resolution is 1:1,000,000. gNATSGO is a gridded combination of SSURGO and STATSGO. gNATSGO is primarily SSURGO data, but where SSURGO is unavailable, STATSGO is used to fill the gaps. The state-wide geodatabases are 10-meter cell sizes and the CONUS database is a 30-meter cell size. 2.1 What mapunits are in an MLRA? If your MLRA uses primarily SSURGO data, the Mapunit in MLRA tool is the best option. It allow you to simply enter your MLRA of interest and define what percent of the total mapunit acreage must be within your MLRA for the mapunit to be considered a member of your MLRA of interest. Note that this tool will make two groups of mapunits if there are more than 2,100 mapunits. This happens because most NASIS queries do not allow for more than 2,100 mapunits to be included in a query. Why not use a NASIS Query that queries components by MLRA, like NASIS &gt; Queries &gt; NSSC Pangaea &gt; Area/Legend/Mapunit/DMU by MLRA? Unfortunately, this is not the most reliable way to determine what mapunits are in an MLRA. Mapunits are assigned to an MLRA via the mapunit area overlap table. These tables are not perfectly populated. Some mapunits are not assigned to an MLRA and others could be assigned to multiple MLRAs. For this reason, using a spatial intersection, as is done in the Mapunit in MLRA tool is the preferred approach. Components are assigned from the same mapunit area overlap tables and therefore suffer from imperfect population of mapunit overlap tables also. Components 2.2 What mapunits are in a Soil Survey Area? Queries by Soil Survey Area are much more reliable than queries by MLRA. As previously mentioned, queries by MLRA are not ideal because the mapunit overlap tables are imperfectly populated. The Soil Survey area corresponds to the legend, and this means that components are reliably associated with Soil Survey Areas. Therefore, lets use the following: NASIS &gt; Query &gt; NSSC Pangaea &gt; Area/Legend/Mapunit/DMU/Pedon/Site/ by areasymbol. Run against National Run against Local Acquire component names and IDs using R. Load the soilDB package and fetch NASIS data library(soilDB) my.mapunits.SSA &lt;- fetchNASIS(from = &quot;components&quot;) Look at the mapunits - the head() function shows just the first six records. Remove the head() function to see all the component names #head(my.components.SSA$) 2.3 Mapping mapunits Using Soil Web and R. "],["components.html", "Chapter 3 Components 3.1 Identify components in MLRA? 3.2 Identify components in Soil Survey Area? 3.3 Existing component, ecosite correlations 3.4 Components correlated to an ecosite of interest? 3.5 Ecological characteristics of components? (non-programmatic) 3.6 Ecological characteristics of components? (programmatic) 3.7 Where do components occur? 3.8 How to correlate components to ecosites? 3.9 How to QC the correlation between", " Chapter 3 Components Components are one of the core concepts in the NRCS ecological workflow. Ecosites are correlated to components. This 3.1 Identify components in MLRA? There are NASIS Queries that allow querying by MLRA. Unfortunately, this is not the best approach. See the section What mapunits are in an MLRA for an explanation of why. Spatial intersection of MLRA boundaries and mapunits is more reliable. Determine the mapunits in the MLRA using the Mapunits in MLRA tool Take the group of mapunits and enter them into Query &gt; MLRA09_Temple &gt; ARE/LMU/MU/DMU by Lmukey list. Run against National Database: Run against Local: Acquire the component names and component IDs using R: Load the soilDB package and fetch NASIS data library(soilDB) my.components.MLRA &lt;- fetchNASIS(from = &quot;components&quot;) ## Warning: Horizon top depths contain NA! Check depth logic with ## aqp::checkHzDepthLogic() ## Warning: Horizon bottom depths contain NA! Check depth logic with ## aqp::checkHzDepthLogic() ## Warning in `hzidname&lt;-`(`*tmp*`, value = &quot;chiid&quot;): horizon ID name (chiid) not ## unique. unique ID not changed. Look at component names - the head() function shows just the first six records. Remove the head() function to see all the component names head(my.components.MLRA$compname) ## [1] &quot;Jokerst&quot; &quot;Doemill&quot; &quot;Rockstripe&quot; ## [4] &quot;Ultic Haploxeralfs&quot; &quot;Honker&quot; &quot;Vallecitos&quot; Look at the component IDs head(my.components.MLRA$coiid) ## [1] &quot;1047328&quot; &quot;1047328&quot; &quot;1047328&quot; &quot;1047329&quot; &quot;1047329&quot; &quot;1047329&quot; 3.2 Identify components in Soil Survey Area? Queries by Soil Survey Area are much more reliable than queries by MLRA. As previously mentioned, queries by MLRA are not ideal because the mapunit overlap tables are imperfectly populated. The Soil Survey area corresponds to the legend, and this means that components are reliably associated with Soil Survey Areas. Therefore, beginning with a query is the preferred approach: Run against National Run against Local Acquire component names and IDs using R. Load the soilDB package and fetch NASIS data library(soilDB) my.components.SSA &lt;- fetchNASIS(from = &quot;components&quot;) Look at component names - the head() function shows just the first six records. Remove the head() function to see all the component names head(my.components.SSA$compname) ## [1] &quot;Littlepete&quot; &quot;Ladderlake&quot; &quot;Terric Cryosaprists&quot; ## [4] &quot;Mendel&quot; &quot;Lackey&quot; &quot;Pigchute&quot; Look at the component IDs head(my.components.SSA$coiid) ## [1] &quot;2045891&quot; &quot;2045891&quot; &quot;2045891&quot; &quot;2045891&quot; &quot;2045891&quot; &quot;2045891&quot; 3.3 Existing component, ecosite correlations Perhaps we want to see what ecosite each component is correlated to. For this example, we will work with all the components in MLRA 18. We will continue from What mapunits are in an MLRA?. You should have the object my.components.MLRA loaded. Load a couple of necessary packages library(dplyr) library(aqp) Now, lets look at the correlations between component ID and ecosite ID. This script takes our components in MLRA 18, pulls out the site level data (allows us to ignore pedon data), and then selects only the columns for component ID and ecosite ID (there are lots of other columns you can choose from, tailor to your needs). Finally we look at just the head() of the comp.ecosite.correlations. If you want to see the full dataframe, remove head(). comp.ecosite.correlations &lt;- my.components.MLRA %&gt;% aqp::site() %&gt;% dplyr::select(coiid, ecosite_id) head(comp.ecosite.correlations) ## coiid ecosite_id ## 1 1047328 R018XA103CA ## 2 1047329 R018XA103CA ## 3 1047374 R018XA104CA ## 4 1047375 F018XA202CA ## 5 1058347 R015XE001CA ## 6 1058348 R015XE026CA 3.4 Components correlated to an ecosite of interest? Perhaps there is a specific ecosite we are interested in and we want to see what components are correlated to that ecosite. Lets say the ecosite is R018XI202CA. We will start with the comp.ecosite.correlations dataframe that we created in the previous example. R018XI202CA &lt;- comp.ecosite.correlations %&gt;% filter(ecosite_id == &quot;F018XA202CA&quot;) head(R018XI202CA) # Again, remove head() to see the full list. ## coiid ecosite_id ## 1 1047375 F018XA202CA ## 2 1122909 F018XA202CA ## 3 1153760 F018XA202CA ## 4 1153763 F018XA202CA ## 5 1153765 F018XA202CA ## 6 1153766 F018XA202CA 3.5 Ecological characteristics of components? (non-programmatic) One of the best ways to do this is a NASIS report: NASIS &gt; Reports &gt; MLRA02_Davis &gt; EXPORT - Ecological site concept data by MUKEY list v3. This report takes mapunit keys (MUKEY) as input. If you are interested in all the components in an MLRA, refer to What mapunits are in an MLRA?. If you are interested in a Soil Survey Area  Run against National In the resulting output (html output in your browser), click anywhere, ctrl + a (select all), ctrl + c (copy) Open Excel, click in top left cell, ctrl + v (paste) Ctrl + a (select all), Insert &gt; Table Now you have a table with lots of ecological characteristics. You can use the column headers to filter in various ways. If you prefer to work in R, save this file as a .csv and read it into R. 3.6 Ecological characteristics of components? (programmatic) Selected set: Determine an appropriate selected set. I am using the https://nroe.shinyapps.io/MapunitsInMLRA/ tool to determine all the mapunits in my MLRA and then using the NASIS Query, NSSC Pangaea &gt; Area/Legend/Mapunit/DMU by record ID - LMAPUNITIID. Load library library(sf) ## Warning: package &#39;sf&#39; was built under R version 4.1.3 ## Linking to GEOS 3.9.1, GDAL 3.2.1, PROJ 7.2.1; sf_use_s2() is TRUE library(aqp) library(dplyr) library(soilDB) library(stringr) Pull data from NASIS selected set nasis_selection &lt;- fetchNASIS(from = &quot;components&quot;, rmHzErrors = FALSE) ## Warning: Horizon top depths contain NA! Check depth logic with ## aqp::checkHzDepthLogic() ## Warning: Horizon bottom depths contain NA! Check depth logic with ## aqp::checkHzDepthLogic() ## Warning in `hzidname&lt;-`(`*tmp*`, value = &quot;chiid&quot;): horizon ID name (chiid) not ## unique. unique ID not changed. Lets start off by removing miscellaneous areas and minor components. This is going to simplify things and remove some of the oddities that may exist in the data. Ecological sciences do not correlate to misc. areas or minor components, so it will not be a loss to us. nasis_selection &lt;- subset(nasis_selection, compkind != &quot;miscellaneous area&quot; &amp; majcompflag == &quot;1&quot;) Horizon level data Create data frame from the horizon level data. This script provides the flexibility to add characteristics of interest. If there are other horizon level data that you are interested in, you can add it following the same syntax shown below. To see what horizon level data is available, type nasis_selection@horizons$ into the console. Horizon level data is summarized into site level info. If you add other horizon level data, make sure it is summarized in a conceptually meaningful way. horizon_df &lt;- data.frame(component = nasis_selection$coiid, texture = nasis_selection$texture, frag_vol = nasis_selection$fragvoltot_r, sand = nasis_selection$sandtotal_r, clay = nasis_selection$claytotal_r, sieve10 = nasis_selection$sieveno10_r, thickness = nasis_selection$hzdepb_r - nasis_selection$hzdept_r, rock_frag = nasis_selection$total_frags_pct, ph_l = nasis_selection$ph1to1h2o_l, ph_r = nasis_selection$ph1to1h2o_r, ph_h = nasis_selection$ph1to1h2o_h, awc_l = nasis_selection$awc_l, awc_r = nasis_selection$awc_r, awc_h = nasis_selection$awc_h) Separate the texture column horizon_df$texture_qualifier &lt;- horizon_df$texture %&gt;% stringr::str_extract(&quot;.*(?=-)&quot;) horizon_df$texture_only &lt;- horizon_df$texture %&gt;% stringr::str_extract(&quot;(?&lt;=-).*&quot;) horizon_df$texture_only &lt;- ifelse(is.na(horizon_df$texture_only), horizon_df$texture, horizon_df$texture_only) Working with texture: We have two goals for texture. One, we want to have a textural modifier where appropriate (i.e., CB, CBV, GR). Two, we want to have a texture (i.e., L, CL, SC). Ultimately, we want a single textural modifier and a single texture to represent the entire soil profile. We are starting off with textural modifiers and textures for each horizon, though. Therefore, we need to consider how to aggregate that data. Textural modifiers - For textural modifiers, we will choose the textural modifier from the thickest soil horizon and that textural modifier will be used as a value that represents the entire profile. Before doing that, we are going to change the depth of horizons that were not textured. For those horizons that were not textured, we are going to change the depth to 0.1 cm. This will prevent textural modifiers from being defined based on a horizon that was not textured. For example, a BR horizon is automatically assigned a depth of 25 cm. Depth of BR has limited ecological significance, and we do not want the texture of the soil profile to be determined by BR conditions. We are also specifically stating that texture is not equal to BR because several horizons that are BR have values of 0 for sand and clay when they should be NAs. horizon_df$thickness_modified &lt;- ifelse(is.na(horizon_df$clay), 0.1, ifelse(horizon_df$texture == &quot;BR&quot;, 0.1, horizon_df$thickness)) Now, we assign the textural modifier from the thickest horizon to the component. summarized_texture_qualifier &lt;- horizon_df %&gt;% dplyr::group_by(component, texture_qualifier) %&gt;% dplyr::summarize(combined_thickness = sum(thickness_modified)) %&gt;% dplyr::ungroup() %&gt;% dplyr::group_by(component) %&gt;% top_n(1, combined_thickness) %&gt;% ungroup() %&gt;% dplyr::select(-combined_thickness) Texture - Now, we are going to assign a texture to the entire profile. For texture, we have quantitative data (sand and clay percentages). This allows us to do a weighted average rather than just choosing the texture from the thickest horizon like we did for texture modifiers. First, we will remove horizons that do not have textures. We will also remove horizons labelled with texture as BR because some of those bedrock horizons have sand and clay percentages entered as zero rather than NA. Then, we group the horizons by the component id and calculate a weighted mean for clay/sand, pH, and rock frag using the horizon thickness as the weighting. weighted_texture &lt;- horizon_df %&gt;% dplyr::filter(!is.na(clay) &amp; !is.na(sand) &amp; texture != &quot;BR&quot;) %&gt;% dplyr::group_by(component) %&gt;% dplyr::summarise(clay_mean_texture = weighted.mean(clay, thickness_modified), sand_mean_texture = weighted.mean(sand, thickness_modified), ph_l_mean = weighted.mean(ph_l, thickness_modified), ph_r_mean = weighted.mean(ph_r, thickness_modified), ph_h_mean = weighted.mean(ph_h, thickness_modified), awc_l_sum = sum(awc_l * thickness_modified), awc_r_sum = sum(awc_r * thickness_modified), awc_h_sum = sum(awc_h * thickness_modified), rock_frag = weighted.mean(rock_frag, thickness_modified), depth_to_restr = sum(thickness_modified)) %&gt;% dplyr::mutate(textural_class = aqp::ssc_to_texcl(clay = clay_mean_texture, sand = sand_mean_texture)) Combine the texture qualifiers and the textures into a dataframe horizon_to_component_data &lt;- dplyr::left_join(summarized_texture_qualifier, weighted_texture) Component level data Here, we change gears and start assembling component level data. component_data &lt;- with(site(nasis_selection), data.frame( coiid = coiid, compname = compname, comppct_r = comppct_r, compkind = compkind, slope_l = slope_l, slope_r = slope_r, slope_h = slope_h, majcompflag = majcompflag, pmkind = pmkind, dmuiid = dmuiid, pmorigin = pmorigin, surf_frag = surface_total_frags_pct, elev_l = elev_l, elev_rv = elev_r, elev_h = elev_h, map_l = map_l, map_rv = map_r, map_h = map_h, maat_l = maat_l, maat_rv = maat_r, maat_h = maat_h, ffd_l = ffd_l, ffd_rv = ffd_r, ffd_h = ffd_h, aspectccwise = aspectccwise, aspectrep = aspectrep, aspectcwise = aspectcwise, landform = landform_string, taxtemp = taxtempregime, drainagecl = drainagecl, ecosite = ecosite_name, ecosite_id = ecosite_id ) ) Collect restriction data restriction_data &lt;- restrictions(nasis_selection) %&gt;% dplyr::select(coiid, reskind, resdept_l, resdept_r, resdept_h, reshard) %&gt;% subset(!grepl(&quot;noncemented&quot;, reshard)) %&gt;% dplyr::group_by(coiid) %&gt;% arrange(resdept_r) %&gt;% dplyr::slice(1) Merge component data and restriction data restriction_data$coiid &lt;- as.character(restriction_data$coiid) component_data &lt;- left_join(component_data, restriction_data) ## Joining, by = &quot;coiid&quot; Merge horizon data and component data all_data &lt;- horizon_to_component_data %&gt;% dplyr::rename(coiid = component) %&gt;% left_join(component_data) %&gt;% dplyr::select(coiid, compname, ecosite, ecosite_id, landform, pmkind, pmorigin, taxtemp, textural_class, texture_qualifier, rock_frag, surf_frag, depth_to_restr, drainagecl, slope_l, slope_r, slope_h, ph_l_mean, ph_r_mean, ph_h_mean, elev_l, elev_rv, elev_h, map_l, map_rv, map_h, maat_l, maat_rv, maat_h, ffd_l, ffd_rv, ffd_h ,comppct_r, dmuiid, everything()) Save as csv write.csv(all_data, &quot;C:/Users/Nathan.Roe/Downloads/my_ecosite_report.csv&quot;, row.names = FALSE) 3.7 Where do components occur? 3.8 How to correlate components to ecosites? 3.9 How to QC the correlation between "],["ecosites.html", "Chapter 4 Ecosites 4.1 What ecosites are active in an MLRA? 4.2 Range in characteristics of ecosites 4.3 Mapping ecological sites 4.4 Associated sites", " Chapter 4 Ecosites 4.1 What ecosites are active in an MLRA? This process is going to be a very simple addition to the process of Identfying components in an MLRA, beginning with the object created in that step, my.components.MLRA. Library library(aqp) Then, we simply need to call the ecosite IDs or ecosite names, depending on your preference. Remember, remove head() to see the full list. head(my.components.MLRA$ecosite_id) ## [1] &quot;R018XA103CA&quot; &quot;R018XA103CA&quot; &quot;R018XA104CA&quot; &quot;F018XA202CA&quot; &quot;R015XE001CA&quot; ## [6] &quot;R015XE026CA&quot; head(my.components.MLRA$ecosite_name) ## [1] &quot;Shallow Thermic Volcanic Ridges 30- 40 PZ&quot; ## [2] &quot;Shallow Thermic Volcanic Ridges 30- 40 PZ&quot; ## [3] &quot;Shallow Mesic Volcanic Ridges 39 - 49 PZ&quot; ## [4] &quot;Deep Mesic Mountain Slopes &amp; Summits 40- 55 PZ&quot; ## [5] &quot;Clayey Hills 10-14\\&quot; p.z.&quot; ## [6] &quot;Loamy Slopes 9-12\\&quot; p.z.&quot; There are likely NAs (missing values) in the above list. This is because the above considers components are are minor and miscellaneous. We do not correlate ecosites to components that are minor and miscellaneous. It will likely be more useful to remove minor and miscellaneous componets: my.components.MLRA.reduced &lt;- my.components.MLRA %&gt;% aqp::site() %&gt;% filter(compkind != &quot;miscellaneous area&quot; &amp; majcompflag == &quot;1&quot;) head(my.components.MLRA.reduced$ecosite_id) ## [1] &quot;R018XA103CA&quot; &quot;R018XA103CA&quot; &quot;R018XA104CA&quot; &quot;F018XA202CA&quot; &quot;R015XE001CA&quot; ## [6] &quot;R015XE026CA&quot; head(my.components.MLRA.reduced$ecosite_name) ## [1] &quot;Shallow Thermic Volcanic Ridges 30- 40 PZ&quot; ## [2] &quot;Shallow Thermic Volcanic Ridges 30- 40 PZ&quot; ## [3] &quot;Shallow Mesic Volcanic Ridges 39 - 49 PZ&quot; ## [4] &quot;Deep Mesic Mountain Slopes &amp; Summits 40- 55 PZ&quot; ## [5] &quot;Clayey Hills 10-14\\&quot; p.z.&quot; ## [6] &quot;Loamy Slopes 9-12\\&quot; p.z.&quot; We might also be interested to see how often different ecosites are used: table(my.components.MLRA.reduced$ecosite_id) %&gt;% as.data.frame() %&gt;% dplyr::rename(Ecosite = Var1) %&gt;% arrange(desc(Freq)) %&gt;% head() ## Ecosite Freq ## 1 F022AW007CA 413 ## 2 R017XY902CA 410 ## 3 R017XY905CA 287 ## 4 R017XY903CA 251 ## 5 R017XY904CA 215 ## 6 F018XC201CA 155 Interesting the most used ecosites in MLRA18 are ecosite concepts from MLRAs 22a and 17. 4.2 Range in characteristics of ecosites I created a report that summarizes the characteristics of ecosites. It is organized based on the information that is supposed to be populated in EDIT. Here is a link to a sample report. I have established a methodology allowing you to create reports like the one linked for all of the ecosites in your MLRA within a few short steps. You can also produce the report for just one of your ecosites. For documentation on this methodology, click here. Click on the green Code button and choose Download ZIP. Once you have downloaded to the location of your preference, you can right click &gt; Extract all. You can then open the read_me.docx file. Additionally, you can watch the following YouTube video: 4.3 Mapping ecological sites For this methodology, the ecological site is mapped in all map units containing a component correlated to the ecological site. The alternative would be to map the ecological site only in map units where the dominant component is correlated to the ecological site of interest. I am more interest in the full extent of the ecological site, so I am using the less restrictive of the two. We are starting with the typical selected set from Query &gt; MLRA09_Temple &gt; ARE/LMU/MU/DMU by Lmukey list. Load required packages library(sf) library(maps) library(soilDB) library(dplyr) library(ggplot2) Load the soilDB package and fetch NASIS data my.components.MLRA &lt;- fetchNASIS(from = &quot;components&quot;) ## Warning: Horizon top depths contain NA! Check depth logic with ## aqp::checkHzDepthLogic() ## Warning: Horizon bottom depths contain NA! Check depth logic with ## aqp::checkHzDepthLogic() ## Warning in `hzidname&lt;-`(`*tmp*`, value = &quot;chiid&quot;): horizon ID name (chiid) not ## unique. unique ID not changed. Load a shapefile of your map unit boundaries (the MLRA boundaries cover the whole country, but you will have to change the map unit boundaries to your local map unit shapefile) mapunit_boundaries &lt;- sf::read_sf(&quot;C:/Users/Nathan.Roe/Documents/PES/gSSURGO_CA_2022.gdb&quot;, &quot;mupolygon&quot;) ## Warning in CPL_read_ogr(dsn, layer, query, as.character(options), quiet, : ## GDAL Message 1: organizePolygons() received a polygon with more than 100 parts. ## The processing may be really slow. You can skip the processing by setting ## METHOD=SKIP, or only make it analyze counter-clock wise parts by setting ## METHOD=ONLY_CCW if you can assume that the outline of holes is counter-clock ## wise defined mlra_boundaries &lt;- sf::read_sf(&quot;C:/Users/Nathan.Roe/Documents/PES/MLRA_52_2022/MLRA_52_2022/MLRA_52.shp&quot;) What is your ecological site of interest? (change appropriate to your project) ecosite_of_interest &lt;- &quot;R018XE104CA&quot; What is your MLRA of interest? (change appropriate to your project) mlra_of_interest &lt;- 18 Reduce component data to those associated with ecosite of interest my.components.MLRA.reduced &lt;- aqp::site(my.components.MLRA) %&gt;% filter(ecosite_id == ecosite_of_interest) Reduce mapunits to those associated with ecosite of interest mapunit_boundaries_of_interest &lt;- mapunit_boundaries %&gt;% dplyr::filter(MUKEY %in% my.components.MLRA.reduced$muiid) %&gt;% sf::st_transform(&quot;+proj=longlat +datum=WGS84&quot;) Reduce MLRA boundary to MLRA of interest mlra_boundaries_reduced &lt;- mlra_boundaries %&gt;% dplyr::filter(MLRARSYM == mlra_of_interest) %&gt;% sf::st_transform(&quot;+proj=longlat +datum=WGS84&quot;) Select state of interest (change appropriate to your project, you could select multiple states too) ca &lt;- st_as_sf(maps::map(&quot;state&quot;, fill = TRUE, plot = FALSE)) %&gt;% dplyr::filter(ID == &quot;california&quot;) %&gt;% sf::st_transform(&quot;+proj=longlat +datum=WGS84&quot;) Plot map ggplot() + theme_minimal() + geom_sf(data = ca) + geom_sf(data = mlra_boundaries_reduced) + geom_sf(data = mapunit_boundaries_of_interest, col = &quot;hotpink&quot;, alpha = 0, size = 2) + ggtitle(paste0(&quot;Distribution of ecological site - &quot;, ecosite_of_interest)) 4.4 Associated sites Associated sites are ecological sites that occur in the same area of the landscape. The simplest way to think about this is ecological sites that are adjacent to your ecological site of interest. I am going to present a simple way of addressing this. We can determine what ecological sites occur in the same mapunit as your ecosite of interest. Looking at all the mapunits that your ecological site of interest occurs in, and tallying up all of the other ecological sites that are in shared mapunits, we can come to a metric of what other ecological sites tend to be near your ecological site of interest. In the future, I would like to make some improvements to this, so that it considers adjacent mapunits and considers the length of boundary between mapunits. I am loading components from Query &gt; MLRA09_Temple &gt; ARE/LMU/MU/DMU by Lmukey list. Load the soilDB package and fetch NASIS data library(soilDB) my.components.MLRA &lt;- fetchNASIS(from = &quot;components&quot;) ## Warning: Horizon top depths contain NA! Check depth logic with ## aqp::checkHzDepthLogic() ## Warning: Horizon bottom depths contain NA! Check depth logic with ## aqp::checkHzDepthLogic() ## Warning in `hzidname&lt;-`(`*tmp*`, value = &quot;chiid&quot;): horizon ID name (chiid) not ## unique. unique ID not changed. Reduce data to major components and non-miscellaneous area my.components.MLRA.reduced &lt;- my.components.MLRA %&gt;% site() %&gt;% filter(compkind != &quot;miscellaneous area&quot; &amp; majcompflag == &quot;1&quot;) Reduce to only MLRA18 ecosites MLRA18_ecosites &lt;- my.components.MLRA.reduced$ecosite_id %&gt;% stringr::str_subset(&quot;18X&quot;) %&gt;% unique() Create empty lists for upcoming for loops ecosite_mukeys_list &lt;- list() mus_with_ecosite_list &lt;- list() Create for loop to determine all the mapunits that each ecological site occurs in for(i in MLRA18_ecosites){ ecosite_mukeys_list[[i]] &lt;- my.components.MLRA.reduced %&gt;% dplyr::filter(ecosite_id == i) %&gt;% pull(mukey) } Create a list of dataframes. Each dataframe has the name of the ecological site that it represents. The dataframes contain all of the component data from all of the mapunits that the ecosite occurs in. For example, lets say we have an ecosite named F018XA201CA. The dataframe for F018XA201CA will contain data for all the components that occur in all of the mapunits that F018XA201CA occurs in. That means that many of the components will be components correlated to F018XA201CA, but it will also contain other components not correlated to F018XA201CA. for(i in MLRA18_ecosites){ mus_with_ecosite_list[[i]] &lt;- my.components.MLRA.reduced %&gt;% dplyr::filter(mukey %in% ecosite_mukeys_list[[i]]) } Now, we make a table from all of the ecological site data in each dataframe. associated_sites &lt;- lapply(mus_with_ecosite_list, FUN = function(x){ table(x$ecosite_id) %&gt;% as.data.frame() %&gt;% arrange(desc(Freq)) %&gt;% dplyr::rename(Ecosite = Var1) }) The result is this list called associated_sites. associated_lists has a dataframe for every ecological site, ordered by how frequently the other ecologica sites occur. The table describes all the other ecological sites that occur in the same mapunit as the defined ecological site. Lets take a look at an example associated_sites$F018XA202CA ## Ecosite Freq ## 1 F018XA202CA 19 ## 2 R018XA103CA 6 ## 3 R018XA104CA 3 Here, we can see that we are looking at the ecological site F018XA202CA. The ecological site that most commonly occurs in mapunits containing your ecological siteis your ecological site. That will likely always be the case. The other ecological sites it appears with are R018XA103CA and R018XA104CA - those are actually informative. "],["footnotes-and-citations.html", "Chapter 5 Footnotes and citations 5.1 Footnotes 5.2 Citations", " Chapter 5 Footnotes and citations 5.1 Footnotes Footnotes are put inside the square brackets after a caret ^[]. Like this one.1 5.2 Citations Reference items in your bibliography file(s) using @key. For example, we are using the bookdown package (Xie 2022) (check out the last code chunk in index.Rmd to see how this citation key was added) in this sample book, which was built on top of R Markdown and knitr (Xie 2015) (this citation was added manually in an external file book.bib). Note that the .bib files need to be listed in the index.Rmd with the YAML bibliography key. The RStudio Visual Markdown Editor can also make it easier to insert citations: https://rstudio.github.io/visual-markdown-editing/#/citations References "],["blocks.html", "Chapter 6 Blocks 6.1 Equations 6.2 Theorems and proofs 6.3 Callout blocks", " Chapter 6 Blocks 6.1 Equations Here is an equation. \\[\\begin{equation} f\\left(k\\right) = \\binom{n}{k} p^k\\left(1-p\\right)^{n-k} \\tag{6.1} \\end{equation}\\] You may refer to using \\@ref(eq:binom), like see Equation (6.1). 6.2 Theorems and proofs Labeled theorems can be referenced in text using \\@ref(thm:tri), for example, check out this smart theorem 6.1. Theorem 6.1 For a right triangle, if \\(c\\) denotes the length of the hypotenuse and \\(a\\) and \\(b\\) denote the lengths of the other two sides, we have \\[a^2 + b^2 = c^2\\] Read more here https://bookdown.org/yihui/bookdown/markdown-extensions-by-bookdown.html. 6.3 Callout blocks The R Markdown Cookbook provides more help on how to use custom blocks to design your own callouts: https://bookdown.org/yihui/rmarkdown-cookbook/custom-blocks.html "],["sharing-your-book.html", "Chapter 7 Sharing your book 7.1 Publishing 7.2 404 pages 7.3 Metadata for sharing", " Chapter 7 Sharing your book 7.1 Publishing HTML books can be published online, see: https://bookdown.org/yihui/bookdown/publishing.html 7.2 404 pages By default, users will be directed to a 404 page if they try to access a webpage that cannot be found. If youd like to customize your 404 page instead of using the default, you may add either a _404.Rmd or _404.md file to your project root and use code and/or Markdown syntax. 7.3 Metadata for sharing Bookdown HTML books will provide HTML metadata for social sharing on platforms like Twitter, Facebook, and LinkedIn, using information you provide in the index.Rmd YAML. To setup, set the url for your book and the path to your cover-image file. Your books title and description are also used. This gitbook uses the same social sharing data across all chapters in your book- all links shared will look the same. Specify your books source repository on GitHub using the edit key under the configuration options in the _output.yml file, which allows users to suggest an edit by linking to a chapters source file. Read more about the features of this output format here: https://pkgs.rstudio.com/bookdown/reference/gitbook.html Or use: ?bookdown::gitbook "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
